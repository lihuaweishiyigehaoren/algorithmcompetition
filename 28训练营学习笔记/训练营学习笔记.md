## 训练营学习笔记



通过算法提升自己的能力—解决问题的能力，逻辑思维能力

对未知问题的分析和建模能力

### 自测

图有哪两种常见的建模方法？

邻接矩阵和邻接表

“动态规划”性质？

无后向性



### 算法是程序的灵魂

将文字描述的问题抽象成算法能够使用的数据模型。

掌握设计算法的方法和一些常用技巧。



### 1-1 如何“玩”算法

**玩算法要做到以下几点：**

1、对遇到的特殊问题要能够自己设计出算法实现（可能是一个智力游戏题目，也可能是工作中遇到的实际问题）

2、对于原理公开的知名算法，要能将算法原理翻译成具体的算法代码（如二部图匹配的匈牙利算法）

3、对已有具体实现的算法，要能够设计出合适的数学模型，将算法应用到实际问题中（如遗传算法）

**完整的算法应该包含三个重要的组成部分：**

1、数据模型—最终过渡到用计算机语言的数据结构能够描述问题为止

2、算法逻辑主体

3、输入输出

输入就是把自然语言描述的问题转化为计算机存储或处理的数据，并存入数据模型中

输出就是将计算机处理后的结果（也在数据模型中定义）转化成人类能理解的方式输出

算法的逻辑主体就是具体承载数据处理的代码流程，负责对数据模型中的输入数据进行处理、转换，并得到结果。

这三个组成的核心是数据模型，好的数据模型不仅能准确地描述问题，还能简化算法实现或提高算法的效率。

**根据问题的描述简历数据模型的能力就是玩算法关键，不能对问题进行归纳并抽象出数据模型的，就不能设计出解决问题的算法实现，换句话说，就是缺乏解决实际问题的能力**

##### 建立数学模型的一些惯用做法

把问题抽象成数据模型

**1、信息数字化**

信息数字化就是把自然语言描述的信息，转化成方便代码数据模型表达的数字化信息，这是各种问题模型的一个通用思考方向。

比如：

当问题中出现当问题中出现用“甲、乙、丙、丁”或“A、B、C、D”来标识物品或人物的序列时，就可以考虑用数字 1、2、3、4 来表达它们；

判断结果“大于、等于和小于”，可以用正数、0和负数来表示；

布尔值的真假可以用1和0表示，有和无也可以；

例子：

```c++
/*
警察抓了A、B、C、D四名罪犯，其中一名是小偷，审讯的时候：
A说：“我不是小偷。— x!=0
B说：“C是小偷”。 — x=2
C说：“小偷肯定是D。" — x=3
D说：“C 是在冤枉人。" — x!=3
现在知道四个人中三个人说了真话，一个人说了假话，请判断谁是小偷
*/

// 对于这个问题，首先对A、B、C、D四个人用0—3编号，姐姐将四个人的描述结果用数字量化，如果描述为真，则结果是1，描述为假，结果是0.假设小偷的编号是x，对于四个人的描述，数字化结果是：

int dis_a = (x!=0)? 1:0;
int dis_b = (x == 2)? 1:0;
int dis_c = (x == 3)? 1:0;
int dis_d = 1-dis_c;

// 通过以上量化，则有结果
void who_is_thief()
{
    for (int x = 0; x < 4; x++)
    {
        int dis_a = (x != 0) ? 1 : 0;
        int dis_b = (x == 2) ? 1 : 0;
        int dis_c = (x == 3) ? 1 : 0;
        int dis_d = 1 - dis_c;

        if ((dis_a + dis_b + dis_c + dis_d) == 3)
        {
            char thief = 'A' + x;
            std::cout << "The thief is " << thief << std::endl;
            break;
        }
    }
}
```

**信息数字化是建立数学模型的基础，数字化后的数据和数据模型是相辅相成的两个东西，先要知道有什么数据，才能设计响应的数据模型存储和表达这些数据，而好的数据模型不仅有利于数据的存储和访问，也有利于算法的高效实现**

**2、类比和转化**

使用一个我们熟知的模型来解决未知的问题，很重要。

比如：

```其他
判断n个矩形之间是否存在包含关系是经典的算法几何问题。按照一般的思路，应该是n个矩形两两进行包含判断，但是很显然，这个简单的方法需要n（n-1)次矩形包含判断，时间复杂度是O(n^2).
但是如果知道区间树的概念，就可以将这个问题转化为区间树的查询问题。
1、首先根据矩形的几何位置，利用水平边和垂直边分别构造两颗区间树（根据矩形的几何特征，只需要处理一条水平边和一条垂直边即可）
2、然后将n个矩形的水平边作为被查找元素，依次在水平边区间树中查找，如果找到其他矩形的水平边完整覆盖被查找矩形的水平边，则在垂直边区间树上进一步判断该矩形的垂直边被覆盖的情况。
3、如果存在被查找矩形的水平边和垂直边都被同一个矩形的水平边和垂直边覆盖，则说明这两个矩形存在包含关系。
采用区间树的算法复杂度是 O(nlg(n))，额外的开销是建立区间树的开销，但是只要 n 足够大，这个算法仍然比简单的比较法高效。
```

再比如一个项目管理的例子：

```其他
一个工程项目经过层层结构分解最终得到一系列具体的活动，这些活动之间往往存在复杂的依赖关系，如何安排这些活动的开始顺序，使得项目能够顺利完成是个艰巨的任务。
但是如果能把这个问题转化成有向图，图的顶点就是活动，顶点之间的有向边代表活动之间的前后关系，则只需要使用简单的有向图拓扑排序算法就可以解决这个问题。
一个工程分解出的这么多活动，每个活动的时间都不一样，如何确定工程的最短完工时间？
工程的最短完工时间取决于这些活动中时间最长的那条关键活动路径，从成千上百个活动中找出关键路径看似是个无法下手的问题，但是如果将问题转化为有向图，顶点表示事件，边表示活动，边的权代表活动时间，则可以利用有向图的关键路径算法解决问题。
```



**3、数学问题的建模**

计算几何的问题范围都是整个坐标系，比如直线是向两端无限延伸的，但是对于计算机来说，即便有大数计算库的支持，它能表达的最大范围也是有限的。通常会根据实际应用场景裁剪规模，以便于计算机算法的建模和处理。比如某绘图仪的最大坐标范围是 [−32768,32768]，那就可以定义一个比 −32768 还小的数作为负无穷大，定义一个比 32768 还大的数作为正无穷大，这样直线就可以作为一个两端超过区间 [−32768,32768] 的大线段来建模，对于坐标范围是 [−32768,32768] 来说，模型符合直线的特征，对于计算机来说，这是一条数据模型能表达和存储的线段。

对于涉及数学公式的建模，相对比较简单，只要定义的数据结构能表达公式描述的各项属性即可。

**需要注意的是，很多公式是隐含着无穷数列的特征的，在建模时需要增加约束条件，使得问题能在某个范围内用算法解决。**

例如：n次二项式的展开式的系数问题

![二项式](.\二项式.png)

多项式项数与n相关（n+1)

受制于空间的限制，考虑数据模型的时候需要限制n的最大值

观察每个展开项可知，需要存储的数据有多项式系数、a的幂和b的幂三个属性，因此定义的数据结构要有相对应的条目这些属性，可以定义每一项的数据结构：

```c++
typedef struct
{
    int c;// 系数
    int am; // a幂
    int bm;
}ITEM
```

需要一个列表来存储各项的数据，显然列表不存在频繁删除和插入操作，可以选择用数据作为数据模型。限制n最大为32.

最终定义的数据模型为：

```C++
ITEM items[N]; // N<32;
```

![杨辉三角](D:\usegit\github\algorithmcompetition\28训练营学习笔记\杨辉三角.png)

根据定义的数据类型items，求二项式展开式各项系数和幂的算法实现也水到聚成了：

```C++
if(n == 0)
{
    items[0] = {1,0,0}; // 初始化结构体
    return;
}

// 从第一阶开始递推到第n阶
for(unsigned int i = 1; i <= n;i++)
{
    unsigned int nc = i+1;// 每一阶的项数
    items[nc-1] = {1,0,i}; // 末项
    
    // 倒着递推第二项到第n-1项的值，实际下标范围是[1,nc-2],不需要额外的存储空间转存
    for(unsigned int j = nc-2;j>0;j--)
    {
        unsigned int c = items[j].c + tems[j-1].c;
        item[j] = {c,i-j,j};
    }
    items[0] = {1,i,0} // 首项
}
```

计算机也无法直接表示大小和不等于这样的关系，对于不等式的建模，通常是转换成减法，然后对结果进行正、负的判断。对于方程也是一样的，通常将方程转换成 f(x)=0 的形式建模，模型会比较简单。



**4、图论算法的建模**

图论相关的算法也是非常典型的一类问题。描述图的数据结构最常用的是邻接矩阵和邻接链表两种形式.

邻接矩阵一般由一个一维的顶点信息表和一个二维的邻接关系表组成，根据实际问题的情况，还可以增加其他属性，如顶点个数和边的个数等。

一个典型的邻接矩阵数据模型的定义：

```C++
typedef struct
{
    int vertex[MAX_VERTEX];// 顶点信息表
    int edge[MAX_VERTEX][MAX_VERTEX]; // 边信息表
    int numV; // 顶点数
    int numE; // 边数
}GRAPH；
```

如果你使用的编程语言中数组的属性中包含元素个数，那么表示顶点数的 numV 属性就没有必要，同样，表示边数的 numE 属性也不是必需的。

如果问题中关于顶点信息除了编号，还有其他信息，那么顶点信息表的元素类型就不能简单用 int 类型了，而是要根据题目给出的信息做相适应的修改。

比如与地图有关的问题，通常作为顶点的每个城市有很多属性，如城市名称、公路出口个数和入口个数等，就需要定义相关的顶点数据结构

比如包含了城市名称的顶点信息：

```c++
typedef struct
{
    std::string name;
    int node;
}VERTEX

VERTEX vertex[MAX_VERTEX];  //顶点信息表
```

表示边信息的矩阵，每个元素是边的权重，对于不相邻的顶点，权重一般是一个特殊值。

如果边的信息除了权重，若还有其他信息，则需要定义与之相适应的数据结构来描述边的信息。

比如有个求最优解的规划类题目，城市之间除了距离，还有交通困难指数，比如是水路、山路还是平地等信息，

此时边的定义就可以改成如下代码：

```C++
typedef struct
{
    int weight;
    int traffic_type;
}EDGE

EDGE edge[MAX_VERTEX][MAX_VERTEX]; //边信息表
```

使用邻接矩阵定义图，优点是顶点之间的边的信息很容易获取，如果你要处理的问题需要频繁地确定顶点之间的连接信息，那么使用邻接矩阵是一个比较好的选择。

邻接矩阵的缺点是它是一个稀疏矩阵，当顶点比较多的情况下，对存储空间的浪费比较严重。

邻接表是一种顺序分配和链式分配相结合的数据结构，顶点信息顺序存放，每个顶点相邻的顶点信息，则通过一个链表链接到该顶点的邻接点域。一个典型的邻接表数据模型如下：

```c++
typedef struct EDGE
{
    int node;  //边的对应顶点
    int weight;
    EDGE *nextEdge;  //下一条边的信息
}EDGE;

typedef struct
{
    int node;
    EDGE *firstEdge; //第一个边的信息
}VERTEX;

typedef struct 
{
    VERTEX vertex[MAX_VERTEX]; //顶点列表
    int numV; //顶点数
    int numE; //边数
}GRAPH;
```

### 1-2 算法设计常用思想之贪婪法

模式作为算法演进的一些固定的思路，它提供了一些构造算法的常用思想。常用的算法设计思想有迭代法、贪婪法、穷举搜索法、递推法、递归法、回溯法、分治法、动态规划法等，这一课将介绍贪婪法。

#### 基本思想

贪婪法（Greedy Algorithm），又称贪心算法。

这种方法模式一般将求解过程分成若干个步骤，但每个步骤都应用贪心原则，选取当前状态下最好的或最优的选择（局部最有利的选择），并以此希望最后堆叠出的结果也是最好或最优的解。

贪婪法的每次决策都以当前情况为基础并根据某个最优原则进行选择，**不从整体上考虑其他各种可能的情况**。

一般来说，这种贪心原则在各种算法模式中都会体现，这里单独作为一种方法来说明，是因为贪婪法对于特定的问题是非常有效的方法。

贪婪法和动态规划法以及分治法一样，都需要对问题进行分解，定义最优解的子结构。

但是与其他方法最大的不同在于，**贪婪法每一步选择完局部最优解之后就确定了，不再进行回溯处理**，也就是说，每一个步骤的局部最优解确定以后，就不再修改，直到算法结束。

因为不进行回溯处理，贪婪法只在很少的情况下可以得到真正的最优解，比如**最短路径问题、图的最小生成树问题**。在大多数情况下，由于选择策略的“短视”，贪婪法会错过真正的最优解，而得不到问题的真正答案。但是贪婪法简单、高效，省去了为找最优解可能需要的穷举操作，**可以得到与最优解比较接近的近似最优解**，通常作为其他算法的辅助算法来使用。

#### 步骤

- 建立对问题精确描述的数学模型，包括定义最优解的模型；
- 将问题分解为一系列的子问题，同时定义子问题的最优解结构；
- 应用贪心原则确定每个子问题的局部最优解，并根据最优解的模型，用子问题的局部最优解堆叠出全局最优解。

定义最优解的模型通常和定义子问题的最优结构是**同时进行的**

最优解的模型一般都体现了最优子问题的分解结构和堆叠方式。

对于子问题的分解有多种方式，有的问题可以按照问题的求解过程一步一步进行分解，每一步都在前一步的基础上选择当前最好的解，每做一次选择就将问题简化为一个规模更小的子问题，当最后一步的求解完成后就得到了全局最优解。还有的问题可以将问题分解成相对独立的几个子问题，对每个子问题求解完成后再按照一定的规则（比如某种公式或计算法则）将其组合起来得到全局最优解。

例如：

```c++
/*
找零钱问题；
某国发行的货币有 25 分、10 分、5 分和 1 分四种硬币，如果你是售货员且要找给客户 41 分钱的硬币，如何安排才能找给客人的钱既正确且硬币的个数又最少？
这个问题的子问题定义就是从四种币值的硬币中选择一枚，使这个硬币的币值和其他已经选择的硬币的币值总和不超过 41 分钱。子
问题的最优解结构就是在之前的步骤已经选择的硬币再加上当前选择的一枚硬币。
当然，选择的策略是贪婪策略，即在币值总和不超过 41 的前提下选择币值最大的那种硬币。按照这个策略，第一步会选择 25 分的硬币一枚，第二步会选择 10 分的硬币一枚，第三步会选择 5 分的硬币一枚，第四步会选择 1 分的硬币一枚，总共需要 4 枚硬币。
*/

/*
上面的例子得到的确实是一个最优解，但是很多情况下贪婪法都不能得到最优解。同样以找零钱为例，假如，某国货币发行为 25 分、20 分、5 分和 1 分四种硬币，这时候找 41 分钱的最优策略是 2 枚 20 分的硬币加上 1 枚 1 分硬币，一共 3 枚硬币，但是用贪婪法得到的结果却是 1 枚 25 分硬币、3 枚 5 分硬币和 1 枚 1 分硬币，一共 5 枚硬币。
*/
```

#### 贪婪法例子：0-1背包问题

问题描述：

有 N 件物品和一个承重为 C 的背包（也可定义为体积），每件物品的重量是 wi，价值是 pi，求解将哪几件物品装入背包可使这些物品在重量总和不超过 C 的情况下价值总和最大？

背包问题（Knapsack Problem）是此类组合优化的 NP 完全问题的统称，如货箱装载问题、货船载物问题等，因问题最初来源于如何选择最合适的物品装在背包中而得名，这个问题隐含了一个条件，每个物品只有一件，也就是限定每件物品只能选择 0 个或 1 个，因此又被称为 0-1 背包问题。

具体的例子：

```c++
/*
有一个背包，最多能承载重量为 C=150 的物品，现在有 7 个物品（物品不能分割成任意大小），编号为 1~7，重量分别是 wi=[35,30,60,50,40,10,25]，价值分别是 pi=[10,40,30,50,35,40,30]，现在从这 7 个物品中选择一个或多个装入背包，要求在物品总重量不超过 C 的前提下，所装入的物品总价值最高。
分析：
这个问题的数学模型非常简单，就是一个承重是 C 的背包和 n 个物品，每个物品都有重量和价值两个属性。
但是在对问题分析的过程中，我们发现，每个物品还需要一个状态用于标记该物品的选择状态，以确定该物品是否已经被选进背包了，状态是 1 表示物品已经被装到包里了，后续的选择不要再考虑这个物品了。需要特别说明的是状态值为 2 的情况，这种情况表示用当前策略选择的物品导致总重量超过了背包承重量，在这种情况下，如果放弃这个物品，按照策略从剩下的物品中再选一个，有可能就能满足背包承重的要求。因此，设置了一个状态 2，表示当前选择物品不合适，下次选择也不要再选这个物品了。
*/

// 描述每个物品的数据结构 OBJECT 定义为：
typedef struct
{
    int weight;
    int price;
    int status; // 0-未选中，1—已选中；2—已经不可选
}OBJECT;

// 背包问题的定义，背包问题包括两个属性，一个是可选物品列表，另一个是背包总的称重量
// 简单定义背包问题数据结构如下：
typedef struct
{
    std::vector<OBJECT> objs;
    int totalC;
}KNAPSACK_PROBLEM;

// 这就是该问题的数学模型！！！
```

确定数学模型之后，接下来就要确定子问题了。

根据题意，本题的子问题可以描述为：

在背包承重还有 C’ 的情况下，选择一个还没有被选择过，且符合贪婪策略的物品装入背包。每选择一个物品 p[i]，都要调整背包的承重量 C’=C’-p[i].weight，问题的初始状态是 C’=150，且所有物品都可以选择。

假如选择了一个重为 35 的物品后，子问题就变成在背包容量 C’ 是 115 的情况下，从剩下 6 件物品中选择一个物品。

确定了子问题的描述，算法的整体实现过程就是按照选择物品装入背包的过程，按部就班地一步一步解决子问题，直到背包不能再装入物品或所有物品都已经装入背包时，结束算法。

**那么如何选择物品呢？这就是贪婪策略的选择问题。**

对于本题，常见的贪婪策略有三种：

第一种策略是根据物品价值选择，每次都选价值最高的物品，根据这个策略最终选择装入背包的物品编号依次是 4、2、6、5，此时包中物品总重量是 130，总价值是 165。

第二种策略是根据物品重量选择，每次都选择重量最轻的物品，根据这个策略最终选择装入背包的物品编号依次是 6、7、2、1、5，此时包中物品总重量是 140，总价值是 155。

第三种策略是定义一个价值密度的概念，每次选择都选价值密度最高的物品，物品的价值密度 si 定义为 pi/wi，这 7 件物品的价值密度分别为 si=[0.286,1.333,0.5,1.0,0.875,4.0,1.2]。根据这个策略最终选择装入背包的物品编号依次是 6、2、7、4、1，此时包中物品的总重量是 150，总价值是 170。

**算法实现**

```c++
/*
GreedyAlgo() 函数是贪婪算法的主体结构，包括子问题的分解和选择策略的选择都在这个函数中。
能够明显看出来这个算法使用了迭代法的算法模式，当然，这个算法主体的实现还可以使用递归法，正如函数所展示的那样，它可以作为此类问题的一个通用解决思路：
*/
void GreedyAlgo(KBAPSACK_PROBLEM *problem,SELECT_POLICY spFunc)
{
    int idx;
    int ntc = 0;
    
    //spFunc 每次选择最符合策略的那个物品，选后再检查
    while((idx = spFunc(probelm->objs,proble->totalC-ntc)) != -1)
    {
        // 所选物品是否都满足背包称重要求?
        if((ntc + problem->obj[idx].weight) <= problem->totalC)
        {
            problem->objs[idx].status = 1;
            ntc += problem->objs[idx].weight;
		}
        else
        {
            // 不能选这个物品了，做个标记重新选
            problem->objs[idx].status = 2;
        }
	}
    
    PrintResult(problem->objs);
}

/*
spFunc 参数是选择策略函数的接口，通过替换这个参数，可以实现上文提到的三种贪婪策略，分别得到各种贪婪策略下得到的解。以第一种策略为例，每次总是选择 price 最大的物品，可以这样实现：
*/
int Choosefunc1(std::vector<OBJECT>& objs,int c)
{
    int index = -1;// -1表示背包容量已满
    int mp = 0;
    for(int i = 0; i<static_cast<int>(objs.size());i++)
    {
        if((objs[i].status == 0) && (objs[i].price > mp))
        {
            mp = objs[i].price;
            index = i;
		}
    }
    
    return index;
}
```

看起来第三种策略取得了最好的结果，和动态规划方法得到的最优结果是一致的.

但是实际上，这只是对**这组数据的验证结果**而已，如果换一组数据，结果可能完全相反。当然，对于一些能够证明贪婪策略得到的就是最优解的问题，应用贪婪法可以高效地求得结果，比如**求最小生成树的 Prim 算法和 Kruskal 算法**。

在大多数情况下，贪婪法受自身策略模式的限制，通常很难直接求解全局最优解问题，也很难用于多阶段决策问题。贪婪法只能得到比较接近最优解的近似最优解，但是作为一种启发式辅助方法在很多算法中都得到了广泛的应用，很多常用的算法在解决局部最优决策时，都会应用到贪婪法。比如 Dijkstra 的单源最短路径算法在从 dist 中选择当前最短距离的节点时，就是采用的贪婪法策略。事实上，在任何算法中，只要在某个阶段使用了只考虑局部最优情况的选择策略，都可以理解为使用了贪婪算法。

### 1-3 算法设计常用思想之分治法

很多问题得到广泛应用，比如**最轻、最终问题（在一堆形状相同的物品中找出最重或者最轻的哪一个），矩阵乘法、大整数乘法以及排序（例如，快速排序和归并排序）**。

除此之外，这个技巧也是许多高效算法的基础，比如**快速傅立叶变换算法和 Karatsuba 乘法算法。**

#### 应用目的

其一是通过分解问题，使得无法着手解决的大问题变成容易解决的小问题

其二是通过减小问题的规模，降低解决问题的复杂度（或计算量）

计算 N 个采样点的离散傅立叶变换，需要做 N2 次复数乘法，但是将其分解成两个 N/2 个采样点的离散傅立叶变换，则只需要做 (N/2)2 +(N/2)2 = N2/2 次复数乘法，做一次分解就使得计算量减少了一半，这正是快速傅立叶变换（FFT）的实现思想，通过减小问题的规模来减少计算量，以降低问题的复杂度。

#### 步骤

- **分解**：将问题分解为若干个规模较小，相互独立且与原问题形式相同的子问题，确保各个子问题的解具有相同的子结构。
- **解决**：如果上一步分解得到的子问题可以解决，则解决这些子问题，否则，对每个子问题使用和上一步相同的方法再次分解，然后求解分解后的子问题，这个过程可能是一个递归的过程。
- **合并**：将上一步解决的各个子问题的解通过某种规则合并起来，得到原问题的解。

#### 能使用分治法解决的问题特点

第一个特点是问题可以分解为若干个规模较小的相同问题，并且这个分解关系可以用递归或递推的方式逐级分解，直到问题的规模小到可以直接求解的程度。这里说的相同问题，并不是说分解后的子问题与原问题完全一样，这里说的相同只是问题的结构相同，比如原问题有四个属性，分解后规模较小的子问题也应该具有四个相同的属性，不同的只是各个属性的范围和规模。

第二个特点是子问题的解可以用某种方式合并出原始问题的解。这很容易理解，如果不能合并出原始问题的解，那么子问题的划分和求解就没有意义了。

例如：

 Karatsuba 大整数乘法算法，其分解思想是将两个参与计算的 n 位大数各自分成两部分：a + b 和 c + d，其中，a 和 c 分别是这两个大整数的整数幂部分，b 和 d 分别是它们的剩余部分，然后利用乘法的分解公式：(a + b)(c + d) = ac + ad + bc + bd，将其分解为四次小规模大数的乘法计算，并且利用一个小技巧将其化解成三次乘法和少量移位操作。最终结果的合并思想就是用几次加法对小规模乘法的结果进行求和，得到原始问题的解。

#### 实现方式

**递归** —比如快排

不用递归是不是就不能用分治法了？当然不是，快速傅立叶变换算法就没有用递归。很多算法都有自己的非递归实现方式，是否用了递归方法不是判断是不是分治法的必要条件。即便是一些使用了递归方法的算法，也都可以用一个自己构造的栈将其改编为非递归方法，比如快速排序就有很多用栈实现的非递归方法。Robert Sedgewick 在其著作《算法：C语言实现》一书中就给出了一种快速排序的非递归高效算法，有兴趣的读者可阅读此书，了解一下算法实现。

#### 例子

问题：

```C++
/*
给定一个没有重复字母的字符串，输出该字符串中字符的所有排列。假如给定的字符串是“abc”，则应该输出“abc”、“acb”、“bac”、“bca”、“cab”和“cba”六种结果
*/

// 分析
/*
首先分析这是一个全排列问题，解决这个问题我们的常用策略是每次选择固定一个字符，然后对剩下的两个字符进行排列。比如这个三个字母的字符串，我们首先选择固定 a，然后对 bc 进行排列，可以得到“abc”和“acb”两个结果；然后选择固定 b，对 ac 进行排列，可以得到“bac”和“bca”两个结果；最后选择固定 c，对 ab 排列，可以得到“cab”和“cba”两个结果。
不知道大家有没有意识到，这其实就是使用了分治法的思想在解决问题。三个字符排列，我们人脑可能处理不过来，但是我们固定一个字母后，把问题的规模减小为两个字符的排列，两个字符的排列只有两种结果，是可以解决的问题；然后我们将小问题的结果与固定的字母组合在一起，就可以得到原始问题，即三个字符的排列结果。分治法分解子问题，并不是一定要用某种方式均匀分解原始问题，哪怕是每次只能将原始问题的规模变小一点，也是一种分解子问题的方法。
*/

```

回到我们这个问题上，对字符串类问题分解子问题，通常考虑的方法有两个。

- 一个方法是用字符串的开始位置和字符串的长度表示一个子字符串，对于一个长度为 n 的字符串，用这种方法定义的子问题就是“从位置 i 开始，长度为 m 的字符串，其中，1⩽i<n，0<m⩽n”，原始问题就是从位置 1 开始，长度为 n 的字符串。
- 另一个方法是用字符串的位置区间来表示一个子字符串，同样对于一个长度为 n 的字符串，用这种方法定义的子问题就是“从位置 i 开始，到位置 j 结束的字符串，其中，1⩽i<n,i⩽j<n,i⩽j⩽n”，原始问题就是从位置 1 开始到位置 n 结束的字符串。考虑到很多编程语言中索引位置都是从 0 开始，上述描述中的索引位置要做 -1 修正，读者应该能够理解，接下来的例子用 C++ 实现算法，就会体现这一点。

对于这个问题，我们选择用区间的方法定义子问题，即用字符位置索引区间 [begin, end] 表示子问题

选好子问题的表达方式，接下来就要考虑如何分解子问题

根据之前的分析，我们采用每次固定一个字符，然后将剩下的字符串作为一个子问题进行全排列的方式分解子问题。因为每个字符都要被“固定”一次，所以算法实现的方法是用一个循环对子问题 [begin, end] 区间上的每个字符都选择一次。因为大多数编程语言都没有提供直接的方法能够将一个字符固定，同时将剩下的内容重组为一个连续的字符串。

所以很显然，这里面就会有一个实现上的困难需要克服，即**如何选中一个字符固定，还要让剩下的字符保持连续，成为子问题所描述的字符串**。我们采用的方法是将问题区间 [begin, end] 中的 begin 位置作为选中的固定字符位置，将除了这个位置之外的问题区间 [begin+1, end] 作为子问题进一步处理。如果被选中的固定字符不在 begin 位置，则交换两个字符的位置，使得被选中的固定字符位于 begin 位置。

解决了子问题的分解，接下来要考虑子问题的求解。分解的目的是为了减小问题的规模，直到问题能够求解，对于这个字符串排列问题，当子问题的规模减小到只有一个字符的时候，子问题就可以求解了。

因为我们处理方式是从前向后，每次固定 begin 位置的字符，然后将区间 [begin+1, end] 作为子问题进一步处理，所以当 begin 位置和 end 位置相同的时候，就说明字符串只有一个字符了，这时就不需要再分解子问题了。因为这个问题的特点，它不需要显式求解子问题，只需在子问题变成只有一个字符的字符串时输出这个字符串即可，并且因为之前分解子问题的时候，每个位置都已经固定好字符，所以当 begin 位置和 end 位置相同的时候，就实际得到了一个全排列结果。

**实现**

```c++
/*
算法实现的主体就是一个可递归调用的 Permutation() 函数 
Permutation() 函数解决字符串 chList 中从 begin 位置开始到 end 位置结束的字符串的全排列问题，
要求解原始问题，只需将 begin 设置成 0，将 end 设置成字符串长度 -1 即可（字符串长度 -1 就是字符串最后一个字符的索引位置）。
递归展现出了无与伦比的优雅，最后的算法实现只要十几行代码就搞定了
*/

void Swap(std::string& chList, int pos1, int pos2)
{
    if(pos1 != pos2)
    {
        auto tmp = chList[pos1];
        chList[pos1] = chList[pos2];
        chList[pos2] = tmp;
    }
}

// 将字符串[begin,end]区间的子串全排列
void Permutation(std::string & chList, int begin,int end)
{
    if(begin == end) // 只剩下一个字符了，不需要排列了，直接输出当前的结果
    {
        std::cout << chList <<std::endl;
    }
    
    for(int i = begin; i <= end; i++)
    {
        Swap(chList,begin,i); // 把第i个字符换到begin位置，将begin+1看做新的字符串开始
        Permutation(chList,begin+1,end); // 求解子问题
        Swap(chList,begin,i); // 再挑选下一个固定字符串之前，需要换回来
	}
}

int main()
{
    std::string cl = "abcd";
    Permutation(cl,0,cl.length());// 原始问题的规模是从0位置开始的整个字符串
    return 0;
}
```



### 1-4 算法设计思想之动态规划法

#### 概念

动态规划（Dynamic Programming）是解决多阶段决策问题常用的最优化理论，动态规划和分治法一样，也是通过定义子问题，先求解子问题，然后在由子问题的解组合出原问题的解。

但是它们之间的**不同点**是分治法的子问题之间是相互独立的，而动态规划的子问题之间存在堆叠关系（递推关系式确定的递推关系）。

动态规划方法的**原理**是把多阶段决策过程转化为一系列的单阶段决策问题，利用各个阶段之间的递推关系，逐个确定每个阶段的最优化决策，最终堆叠出多阶段决策的最优化决策结果。

动态规划问题有很多**模型**，常见的有线性模型、（字符或数字）串模型、区间模型、状态压缩模型，等等，本节课后面介绍的**最长公共子序列问题**，就是一个典型的**串模型**。

#### 约束

动态规划比穷举高效，这一点在很多情况下都得到了印证，但不一定。

动态规划法对所有子问题求解的内在机制其实是一种**广域搜索**，其效率在很大程度上还是取决于问题本身。

每种方法都有自身的局限性，动态规划法也不是万能的。

动态规划**适合求解**多阶段（状态转换）决策问题的最优解，也可用于含有线性或非线性递推关系的最优解问题，但是这些问题都必须满足**最优化原理和子问题的“无后向性”**。

#### 最优化原理

最优化原理其实就是**问题的最优子结构**的性质，如果一个问题的最优子结构是不论过去状态和决策如何，对前面的决策所形成的状态而言，其后的决策必须构成最优策略。

也就是说，不管之前的决策是否是最优决策，都必须保证**从现在开始的决策是在之前决策基础上的最优决策**，则这样的最优子结构就符合最优化原理

#### 无后向性

所谓“无后向性”，就是当各个阶段的子问题确定以后，对于某个特定阶段的子问题来说，它之前各个阶段的子问题的决策只影响该阶段的决策，对该阶段之后的决策不产生影响。

淡化一下阶段的概念，只强调状态（决策状态）

多阶段决策过程中，随着子问题的划分会产生很多状态，对于某一个状态 S 来说，只要 S 状态确定了以后，S 以后的那些依靠 S 状态做最优选择的状态也就都确定了，S 之后的状态只受 S 状态的影响。也就是说，无论之前是经过何种决策途径来到了 S 状态，S 状态确定以后，其后续状态的演化结果都是一样的，不会因为到达 S 状态的决策路径的不同而产生不同的结果，这就是无后向性。

#### 基本思想

和分治法一样，动态规划解决复杂问题的思路也是先对问题进行分解，然后通过求解小规模的子问题再反推出原问题的结果。

但是动态规划分解子问题**不是简单地按照“大事化小”的方式进行的**，而是沿着决策的阶段来划分子问题，决策的阶段可以随时间划分，也可以随着问题的演化状态来划分。

分治法要求子问题是互相独立的，以便分别求解并最终合并出原始问题的解。分治法对所有的子问题都“一视同仁”地进行计算求解，**如果分解的子问题中存在相同子问题，就会存在重复求解子问题的情况**。

与之相反，动态规划法的子问题不是互相独立的，**子问题之间通常有包含关系，甚至两个子问题可以包含相同的子子问题**。

比如，子问题 A 的解可能由子问题 C 的解递推得到，同时，子问题 B 的解也可能由子问题 C 的解递推得到。对于这种情况，动态规划法对子问题 C 只求解一次，**然后将其结果保存在一张表中（此表也被称为备忘录）**。

当求解子问题 A 或子问题 B 的时候，如果发现子问题 C 已经求解过（在备忘录表中能查到），则不再求解子问题 C，而是直接使用从表中查到的子问题 C 的解，避免了子问题 C 被重复计算求解的问题。

动态规划法不像贪婪法或分治法那样有固定的算法实现模式，**线性规划问题和区间动态规划问题的实现方法就完全不同**。作为解决多阶段决策最优化问题的一种思想，可以用带备忘录的穷举方法实现，也可以根据堆叠子问题之间的递推公式用递推的方法实现。



#### 步骤（从算法设计的角度分析）

1. 定义最优子问题（最优解的子结构）
2. 定义状态（最优解的值）
3. 定义决策和状态转换方程（定义计算最优解的值的方法）
4. 确定边界条件

这四个问题解决了，算法也就确定了



#### 例子

##### **0-1背包问题**

**1、定义最优子问题**

定义最优子问题，也就是最优解的子结构，它确定问题的优化目标以及如何决策最优解，并对决策过程划分阶段。

所谓阶段，可以理解为一个问题从开始到解决需要经过的环节，这些环节前后关联。

划分阶段没有固定的方法，根据问题的结构，可以是按照时间或动作的顺序划分阶段，比如《算法导论》书中介绍的“装配线与工作站问题“（训练营第四部分也有详细介绍）；

也可以是按照问题的组合状态划分阶段，比如经典的“凸多边形三角剖分问题”。

阶段划分以后，对问题的求解就变成了各个阶段分别进行**最优化决策**，问题的解就变成按照阶段顺序依次选择的一个决策序列。

对于 0-1 背包问题，每选择装一个物品可以看做是一个阶段，其子问题就可以定义为每次向包中装（选择）一个物品，直到超过背包的最大容量为止。

最长公共子序列问题可以按照问题的演化状态划分阶段，这就需要先定义状态，有了状态的定义，只要状态发生了变化，就可以认为是一个阶段。



**2、定义状态**

状态既是决策的对象，也是决策的结果

对于每个阶段来说，对起始状态施加决策，使得状态发生改变，得到决策的结果状态。

初始状态经过每一个阶段的决策（状态改变）之后，最终得到的状态就是问题的解。

当然，不是所有的决策序列施加于初始状态后都可以得到最优解，只有一个决策序列能得到最优解。

状态的定义是建立在子问题定义基础之上的，因此状态必须满足无后向性要求。必要时，可以增加状态的维度，引入更多的约束条件，使得状态定义满足无后向性要求。

0-1 背包问题本身是个线性过程，但是如果简单将状态定义为装入的物品编号，也就是定义 s[i]为装入第 i 件物品后获得的最大价值，则子问题无法满足无后向性要求，原因是之前的任何一个决策都会影响到所有的后序决策（因为装入物品后背包容量发生变化了），因此需要增加一个维度的约束。

考虑到每装入一个物品，背包的剩余容量就会减少，故而选择将背包容量也包含在状态定义中。

最终背包问题的状态 s[i,j]定义为将第 i 件物品装入容量为 j 的背包中所能获得的最大价值。

对于最长公共子序列问题，如果定义 str1[1…i] 为第一个字符串前 i 个字符组成的子串，定义 str2[1…j] 为第二个字符串的前 j 个字符组成的子串，则最长公共子序列问题的状态 s[i,j]  定义为 str1[1…i] 与 str2[1…j] 的最长公共子序列长度。



**3、定义决策和状态转换方程**

决策就是能使状态发生转变的选择动作，如果选择动作有多个，则决策就是取其中能使得阶段结果最优的那一个。

状态转换方程是描述状态转换关系的一系列等式，也就是从 n−1 阶段到 n 阶段演化的规律。

状态转换取决于子问题的堆叠方式，如果状态定义得不合适，会导致子问题之间没有重叠，也就不存在状态转换关系了。

没有状态转换关系，动态规划也就没有意义了，实际算法就退化为像分治法那样的朴素递归搜索算法了。

0-1 背包问题的决策很简单，那就是决定是否选择第 i 件物品，即判断装入第 i 件物品获得的收益最大还是不装入第 i 件物品获得的收益最大。

如果不装入第 i 件物品，则背包内物品的价值仍然是 s[i−1,j] 状态，如果装入第 i 件物品，则背包内物品的价值就变成了 s[i,j−Vi]+Pi 状态，其中 Vi和 Pi 分别是第 i 件物品的容积和价值，决策的状态转换方程就是：

![决策状态转换方程](.\决策状态转换方程.png)

最长公共子序列问题的决策方式就是判断 str1[i]  和 str2[j]  的关系

如果 str1[i] 与 str2[j] 相同，则公共子序列的长度应该是 s[i−1,j−1]+1，否则就分别尝试匹配 str1[1…i+1]与 str2[1…j]的最长公共子序列，以及 str1[1…i]与 str2[1…j+1]的最长公共子序列，然后取二者中较大的那个值作为 s[i,j] 的值。最长公共子序列问题的状态转换方程就是：

![最长公共子序列状态方程](.\最长公共子序列状态方程.png)

其中，str1[i] 与 str2[j] 相同。

![最长子序列状态方程2](.\最长子序列状态方程2.png)

其中，str1[i]  与 str2[j] 不相同。



**4、确定边界条件**

对于递归加备忘录方式（记忆搜索）实现的动态规划方法，边界条件实际上就是递归终结条件，无需额外的计算。

对于使用递推关系直接实现的动态规划方法，需要确定状态转换方程的递推式的初始条件或边界条件，否则无法开始递推计算。

0-1 背包问题的边界条件很简单，就是没有装入任何物品的状态：

![0-1结束条件](.\0-1结束条件.png)

若要确定最长公共子序列问题的边界条件，要从其决策方式入手，当两个字符串中的一个长度为 0 时，其公共子序列长度肯定是 0，因此其边界条件就是：

![最长子序列结束条件](.\最长子序列结束条件.png)

其中i = 0 或 j=0。

#### 最长公共子序列

**定义：**

一个序列 S，如果分别是两个或多个已知序列的子序列，且是符合此条件的子序列中最长的，则称 S 为已知序列的最长公共子序列。

关于子序列的定义通常有两种方式，

一种是对子序列没有连续的要求，其子序列的定义就是原序列中删除若干元素后得到的序列；

另一种是对子序列有连续的要求，其子序列的定义是原序列中连续出现的若干个元素组成的序列。

求解子序列是非连续的最长公共子序列问题，也是一个十分实用的问题，它可以描述两段文字之间的“相似度”，即它们的雷同程度，从而能够用来辨别抄袭。

下面将介绍对子序列没有连续性要求的情况下应如何用动态规划法来解决最长公共子序列问题。

根据前面的分析，假如有两个字符串 str1[1..m] 和 str2[1..n]，其最长公共子序列问题在某一个决策阶段的状态 s[i,j] 定义为 str1[1…i] 与 str2[1…j] 的最长公共子序列长度 （i<=m, j<=n），这个状态 s[i,j]其实也就是子问题的定义，可以将其描述为：求字符串 str1<1..m>中从第 1 个到第 i（i <= m） 个字符组成的子串 str1<1…i> 和字符串 str2<1..n> 中从第 1 个到第 j(j<=n) 个字符组成的子串 str2<1…j> 的最长公共序列。

接下来要找出子问题的最优序列中状态 s[i,j] 的递推关系。分析 s[i,j]  的递推关系要从 str1[i] 和 str2[j] 的关系入手，根据非连续最长公共子序列问题的定义，如果 str1[i]  和 str2[j]  相同，则 s[i,j]  就是 s[i−1,j−1]  的最长公共序列 ＋1，如果 str1[i] 和 str2[j]  不相同，则 s[i,j]  就是  s[i−1,j] 的最长公共序列和 s[i,j−1] 的最长公共序列中较大的那一个。

最后是确定状态转移递推关系的边界值。很显然，当 str1 和 str2 中任何一个的长度为 0，则其最长公共子序列即为 0，当状态递推到 s[m,n]时，s[m,n] 就是原始问题的最长公共子序列长度。完整的状态转移递推关系如下：

![动态规划过程](.\动态规划过程.png)

DpLcs() 函数是用动态规划法解决最长公共子序列问题的算法实现，从下面的代码中可以看出，两个 for 循环实际上是做了个广域搜索，将所有子序列的结果都求出来了，只有 s[m,n] 代表的是原始问题的最长公共子序列长度。

```c++
int DpLcs(const std::string & str1,const std:string & str2,int s[MAX_STRING_LEN][MAX_STRING_LEN])
{
    std::string::size_type i, j;
    
    for(i = 1;i <= str1.length();i++)
    {
        s[i][0] = 0;
    }
    
    for(j = 1;j <= str2.length();j++)
    {
        s[0][j] = 0;
    }
    
    for(i = 1;i <= str1.length();i++)
    {
        for(j=1;j <= str2.length(); j++)
        {
            if((str1[i - 1] == str2[j - 1]))
            {
                s[i][j] = s[i - 1][j - 1] + 1; 
            }
            else
            {
                s[i][j] = std::max(s[i - 1][j], s[i][j - 1]); 
            }
        }
    }
    
    return s[str1.length()][str2.length()];
}
```

只要确定问题的实质，按照前面给出的四个步骤引导，逐步分析，实现动态规划法的算法就不再是一件很困难的事情了。



### 1-5 算法设计思想之穷举法

某些最优解问题，如果有多个最优解，还只能用穷举法才能把这些最优解都找出来。有时候，为了验证其他算法的解是否正确，也会用穷举法来辅助验证。所以，不要小看穷举法，很多问题在走投无路的情况下，试试穷举法或许是最后的救命稻草。

穷举法虽然思想简单，但是设计一个解决特定问题的穷举法实现却并不简单。首先，解空间或状态空间的定义没有具体的模式，不同问题的解空间形式上也差异巨大；其次，针对不同问题要选择不同的搜索算法，有很多问题的搜索算法并不直观，需要对问题做细致的分析并且依靠丰富的经验才能设计出来。正因为如此，穷举法也被公认为是最“难用”的算法模式。

#### 步骤

- 确定问题的解（或状态）的定义、解空间的范围以及正确解的判定条件；
- 根据解空间的特点来选择搜索策略，逐个检验解空间中的候选解是否正确；



#### 解空间的定义

解空间就是全部可能的候选解的一个约束范围，确定问题的解就在这个约束范围内，将搜索策略应用到这个约束范围就可以找到问题的解。要确定解空间，首先要定义问题的解并建立解的数据模型。

如果解的数据模型选择错误或不合适，则会导致解空间结构繁杂、范围难以界定，甚至无法设计穷举算法。

以 0-1 背包问题为例，问题要求解的答案是背包中物品能获得的最大价值，但是如果简单地将物品的最大价值定为解的数据模型，则解空间内的候选解的范围就是 [0,235]，其中，235 是全部 7 件物品的价值总和。如果对这个解空间穷举，就需要根据每一个价值总和反推出这个价值总和是由哪几个物品组成的，这会使得搜索算法非常麻烦。

如果换一个角度考虑这个问题，将解的数据模型定义为物品的选择状态，用一个 7 元组分别表示 7 件物品的选择状态，0 表示不选择装入该物品，1 表示选择装入该物品，这个题目的最优解是选择 1、2、4、6、7 号物品，用 7 元组表示就是 [1,1,0,1,0,1,1]。

根据这个选择状态，计算最终的物品总价值的方法非常简单，直接求和即可，比前一种方案根据价值总和反推物品选择状态也简单很多。根据状态定义，解空间一共有 128（2727）个状态，非法解判断与合法解的判断，以及最优解的比较算法都非常简单。最重要的是，搜索算法的设计也很简单，n 元组的遍历有递归、多重循环等多种成熟的实现方法可以选择，简单套用即可。

正如上述背包问题定义解的数据模型时展示的方法，很多问题在设计穷举法时都不是直接根据问题的答案设计解空间的数据模型，因为那样会造成穷举算法设计困难，甚至无法实现算法。如果将问题的解扩展为一组状态，通过状态可以简单推出问题的解，并且状态可以通过演变成另一个状态，将解空间转化成一个可以遍历的状态空间，就可以将对问题的解的穷举遍历变成对这个状态空间的的穷举遍历，从而简化算法设计的难度。

在很多情况下，候选解或状态之间不独立，存在各种关联关系并且这些状态之间也没有简单的规律，不能用一套通用的遍历算法把这些状态都事先确定好，但是可以根据状态之间的演化关系，从一种状态推出另一种或几种状态，递归地执行这种状态演化，逐步得到整个解空间。

在这种情况下，解空间通常伴随着搜索算法展开，从一个原始状态开始，逐步扩展至整个解空间。这样的解空间通常被组织成一棵状态树，最终状态就是状态树的叶子节点，从根节点到叶子节点之间的状态转换过程就是问题求解的过程。

对于更复杂的情况，需要用图的一些方法组织和搜索解空间，在这种情况下，解空间就是节点和边的关系空间。

#### 穷举解空间的策略

穷举解空间的策略就是搜索算法的设计策略，根据问题的类型，解空间的结构可能是线性表、集合、树或者图，对于不同类型的解空间，需要设计与之相适应的穷举搜索算法。

简单的问题可以用通用的搜索算法，比如线性搜索算法用于对线性解空间的搜索，广度优先和深度优先的递归搜索算法适用于树型解空间或更复杂的图型解空间。

根据问题的需要设计搜索算法是一件困难重重的事情，没有捷径，只能在常用搜索策略的基础上多实践，多积累。如果选择一种搜索策略，不带任何假设的穷举搜索，不管行不行，眉毛胡子一把抓，把所有可能的解都检查一遍，这样的搜索通常被称为**“盲目搜索”**。

与之对应的是利用某种策略或计算依据，由启发函数策动有目的的搜索行为，这些策略和依据通常能够加快算法的收敛速度，或者能够划定一个更小的、最有可能出现解的空间并在此空间上搜索，这样的搜索通常称为**“启发性搜索”**。

一般来说，为了加快算法的求解，通常会在搜索算法的执行过程中辅助一些剪枝算法，排除一些明显不可能是正确解的检验过程，来提高穷举的效率。

剪枝一个很形象的比喻，如果某一个状态节点确定不可能演化出结果，就应该停止从这个状态节点开始的搜索，相当于状态树上这一分枝就被剪掉了。

除了采用剪枝策略，还可以使用限制搜索深度的方法加快算法的收敛，但是限制搜索深度会导致无解，或错过最优解，通常只在特定的情况下使用，比如博弈树的搜索。

#### 盲目搜索和启发式搜索

对于线性问题的盲目搜索，就是把线性表中的所有算法按照一定的顺序遍历一遍，对于复杂问题的盲目搜索，常用广度优先搜索和深度优先搜索这两种盲目搜索算法。广度优先算法因为需要额外的存储空间，因此在设计算法时要考虑此额外空间的规模，深度优先算法在搜索过程中容易陷入状态循环，导致在一个没有解的子树上“死循环”，一般需要做状态循环的判断和避免，但总的来说，两种策略并无优劣之分，很多情况下可以互换使用。

如果问题的规模比较大，盲目搜索算法的低效常常会导致无法在可接受的时间内完成搜索。如果搜索能够智能化一点，利用搜索过程中出现的额外信息直接跳过一些状态，避免盲目的、机械式的搜索，就可以加快搜索算法的收敛，这就是启发性搜索。启发性搜索需要一些额外信息和操作来“启发”搜索算法，根据这些信息的不同，启发的方式也不同。

比如，如果知道解空间的状态分布呈现正态分布的特征，则可以从分布中间值开始向两边搜索，因为在中间值附近出现最优解的概率更高，这就是启发式搜索。

再比如，搜索过程中选择合适的评估函数，对每个状态节点能演化出解的可能性进行评估，搜索过程中根据这种可能性对待搜索的状态节点排序，也是一种启发式搜索。

再简单一点，如果在某一个层面的搜索能应用贪婪策略，优先选择与贪婪策略符合的状态节点进行搜索，也是一种启发式搜索。著名的A* 寻径算法，就是一种带启发的搜索算法，利用路径评估函数，每次都选择距离出发点最近的位置开始搜索最短路径的下一个位置。

#### 剪枝策略

对解空间穷举搜索时，如果有一些状态节点可以根据问题提供的信息明确地被判定为不可能演化出最优解，也就是说，从此节点开始遍历得到的子树，可能存在正确的解，但是肯定不是最优解，就可以跳过此状态节点的遍历，这将极大地提高算法的执行效率，这就是剪枝策略

应用剪枝策略的难点在于如何找到一个评价方法（估值函数）对状态节点进行评估。

特定的评价方法都附着在特定的搜索算法中，比如博弈树算法中常用的极大极小值算法和“α-β”算法，都伴随着相应的剪枝算法。除了针对特定问题类型的剪枝算法之外，没有可以一统天下的通用评价方法，通常需要根据实际问题小心地分析，确定评价方法。

除了最优解问题，还有一种情况也会用到剪枝策略。对解空间内的状态节点遍历搜索的过程中，会有一些在特定搜索策略下重复出现的状态节点，对这些状态节点如果不做特殊处理，不仅会因为重复处理相同的状态节点而降低效率，还可能会导致深度优先搜索算法“陷入”到某个子树的搜索中无法退出。

举个例子，如果出现对状态 A 搜索得到子状态 B，对状态 B 搜索得到子状态 C，对状态 C 搜索又可得到子状态 A 的情况，就会使得搜索算法陷入“死循环”。在这种情况下，常用的剪枝策略就是找到一种算法对状态计算校验值，通过比较校验值判断是否是已经处理过的状态节点。

#### 剪枝和启发

有些读者会把搜索过程中的剪枝策略也误认为是启发性搜索，其实剪枝不是启发性搜索。

剪枝的原理是在结果已经搜索出来或部分搜索出来（比如树的根节点已经搜索出来了，但是叶子节点还没有搜索出来）的情况下，根据最优解的判断条件，确定这个方向上不可能存在最优解，从而放弃对这个方向的继续搜索。

而启发性搜索通常是根据启发函数给出的评估值，在结果出来之前就朝着最可能出现最优解的方向搜索。它们的差异点在于是根据结果进行判断还是根据启发函数的评估值进行判断。

#### 搜索算法的评估和收敛

穷举法虽然被称为灵活的“通用算法”，但也不是万能的，穷举法最大的敌人是问题的规模。

很多问题，当规模大到一定程度时，使用穷举法就只具有理论上的可行性。

对某些问题，穷举法是最后的办法，但是问题规模又大到无法对解空间进行完整搜索，这时候就需要对搜索算法进行评估，并确定一些收敛原则。

收敛原则是只要能找到一个比较好的解就返回（不求最好），根据解的评估判断是否需要继续下一次搜索。

大型棋类游戏通常面临这种问题，比如国际象棋和围棋的求解算法，想要搜索整个解空间得到最优解目前是不可能的，所以此类搜索算法通常都通过一个搜索深度参数来控制搜索算法的收敛，当搜索到指定的深度时（相当于走了若干步棋）就返回当前已经找到的最好的结果，这种退而求其次的策略也是不得已而为之，在第六部分介绍博弈树和棋类游戏的时候，会具体介绍相关的方法。

#### 例子（百钱买鸡问题）

问题描述：每只大公鸡值 5 个钱，每只母鸡值 3 个钱，每 3 只小鸡值 1 个钱，现在有 100 个钱，想买 100 只鸡，问如何买？有多少种方法？

分析这个问题，首先定义问题的解。原始问题问如何买鸡，实际是在问对于一种买法来说，买的公鸡、母鸡和小鸡分别有多少只。很显然，这个问题的解是由公鸡数量、母鸡数量和小鸡数量三个值组成的三元组：[roosters,hens,chicks]。

定义了问题的解的数据模型，接着要确定问题的解的穷举方法，对于这个问题来说，穷举的方法非常简单，就是对三元组的三个属性的数量分别穷举。

首先是公鸡的数量，因为总共是 100 钱，所以公鸡的数量最多只能买 20 只，对公鸡数量枚举的范围只要限定在 0~20 就可以了；

同样，母鸡的数量最多只能买 33 只，其枚举范围限制在 0~33 之间。

因为三种鸡的总数是 100 只，所以小鸡的数量就不需要枚举了，根据这个关系直接计算出来即可。

根据题目的意思，要使最后的总钱数能凑够整数 100，小鸡的数量必须是 3 的整数倍，所以可以根据这个条件进行一个小小的剪枝处理，最终实现代码如 Buy() 函数所示，第一层 for 循环枚举大公鸡的数量，第二层 for 循环枚举母鸡的数量，两层循环之后再通过总数 100 只的关系计算出小鸡的数量，这样就凑出了一个候选解。枚举到一个候选解之后，就按照是否能满足 100 钱的条件进行检查，如果符合条件就输出一个正确的解，否则继续枚举下一个候选解。

```C++
void Buy()
{
    for (int roosters = 0; roosters <= 20; roosters++)   //枚举大公鸡数量
    {
        for (int hens = 0; hens <= 33; hens++) //枚举母鸡数量
        {
            int chicks = 100 - roosters - hens;  //剩下的就是小鸡数量
            if (((chicks % 3) == 0) //小鸡个数应该是 3 的整数倍，算是个小小的剪枝
                && ((5 * roosters + 3 * hens + chicks / 3) == 100)) //是否凑够 100 钱
            {
                count++;
                std::cout << "买法 " << count << "：公鸡 " << roosters
                                              << ", 母鸡 " << hens
                                              << ", 小鸡 " << chicks << std::endl;
            }
        }
    }

    std::cout << "共有 " << count << " 种买法" << std::endl;
}
```



### 1-6 算法设计常用思想之迭代法

一般在求解一个问题的时候，都是使用明确的方法或计算公式，带入已知量，一次性求得问题的解。

但是如果用计算机解决这些问题，常常因为各种原因无法直接求解，比如求解一元高次方程的问题。

针对这种情况，人们提出了很多迭代法来**近似求解**这类问题，比较常见的有梯度法、最小二乘法和牛顿迭代法，

只要问题的解是**可收敛的（或者是局部可收敛的）**，都可以使用迭代法求解。

数学意义上的迭代法是一种不断用变量的旧值递推新值的过程，其对应的迭代算法也是用计算机解决问题的一种基本方法。

#### 迭代法和递推法的关系

迭代法一般用于求解数学问题，比如求解一元高次方程、线性和非线性方程组和曲线拟合等问题。

迭代的基本点就是迭代公式，一般也理解为递推公式，这常常让人对迭代法和递推法产生混淆，认为这两个概念是等同的。

事实上，这两个概念还是有点差异的，迭代法作为很多数学问题的求解算法，是解决数学问题的一种常用的算法模式，可以独立构成解决问题的算法。

递推法作为一种设计算法的常用思想，没有固定的算法实现模式，通常是与其他算法模式配合形成算法实现。比如线性动态规划问题，一般都有明确的子问题最优解递推公式，递推思想常常作为算法实现的一部分融入到动态规划算法的实现中。

对于迭代法，还有一种更广泛的观点，就是所有使用了迭代思想的算法实现，都可以理解为是使用了迭代法。从这个角度理解，除了线性动态规划算法，遗传算法、退火算法等算法也可归入迭代法的范畴。

#### 基本思想

明确三个要点：

- **确定迭代变量**：迭代变量一般就是要求解的问题的解，利用迭代递推公式可以不断地由旧值递推出新值。根据问题的不同，迭代变量可以是一个，也可以是多个。确定迭代变量，通常还要根据迭代递推关系给出迭代变量的初始值，这一点也很重要。
- **确定迭代递推关系**：迭代递推关系是根据旧值计算新值的**关系或公式**，这是迭代法实现的关键，如果不能确定迭代关系，则无法用迭代法实现算法。
- **确定迭代终止条件**：迭代终止条件是控制迭代过程退出的关键条件。迭代不可能无休止地进行，必须设置迭代终止条件，在适当的时候退出迭代。迭代终止条件一般有三种假设：其一是迭代变量已经求得问题的**精确值**；其二是迭代变量无法得到精确值，但是某个迭代的值的**精度已经满足要求**；其三是指定明确的迭代**计算次数**。迭代算法的具体实现，可根据问题的类型选择迭代终止条件。一般情况下，为了防止迭代关系在某个区间上发散（不收敛）使得算法进入死循环，都会把第三个条件作为异常退出条件和其他迭代终止条件配合使用，也就是说，即使无法得到符合条件的解，只要迭代计算次数达到某个限制值，也退出迭代过程。



#### 例子（计算一个数的平方根）





![迭代例子](.\迭代例子.png)

常用的递推公式如上：

迭代递推关系就是上面的递推公式，

迭代变量就是要计算的平方根xi。

当某次迭代计算后得到的 xi 符合精度要求，则迭代计算终止，

除此之外，为了防止在给出的初始值附近无法收敛，还要给出一个控制迭代计算次数的控制条件。

```C++
std::pair<bool,double> cl_root(double a, double eps)
{
    double xi = a/2.0;// 初始值用a的一半，很多人的选择
    double xt;
    int count = 0;
    do
    {
        xt = xi;
        xi = (xt + (a/xt))/2.0;
        count++;
        if(count >= LOOP_LIMIT)
        {
            return {false,0.0}; // 不收敛返回失败
		}
    }while(std::fabs(xi-xt)>eps);
    
    return {true,xi};
}
```



### 1-7 基础开胃菜

用代码实现的算法可定还会包含一些代码特有的技巧；

这些巧妙构思的代码技巧，有些体现效率，有些体现程序设计的一致性原则，有些则体现软件架构的好思想。

#### 哨兵位

常用在线性表的处理过程中，比如查找和移动数据操作。

哨兵位通常起到两个作用：

一个是作为一个临时存储空间使用

另一个是减少不必要的越界判断，简化算法代码复杂度。

比如环形链表通常会设置一个表头节点，无论向前或向后遍历，均以这个表头节点为遍历越界（重复）的依据，这样维护链表的时候就不需要专门存储一个表头指针，这个表头节点可以理解为哨兵位。

插入排序算法中也会利用表中的 0 号位置作为哨兵位使用，这个位置不仅起到一个临时存储空间的作用，还可以简化插入后移动数据的判断条件。

注意下面的插入排序代码，内层 while 循环移动数据的时候，只需判断当前位置的数是否比 ls[0] 位置大即可，不需要关心 j 的位置是否小于 1 而越界，因为当 j=1 的时候，ls[j−1]>ls[0] 的条件肯定不满足，while 循环就会终止。如果不使用哨兵位，内层移动数据的循环处理代码就需要增加 j 是否越界的判断。

```c++
// 带哨兵位的排序，ls[0]是哨兵位，数据从ls[1]开始存放
void insert_sort(int *ls,int n)
{
    for(int i = 2; i<= n;i++)
    {
        if(ls[i] < ls[i-1])
        {
            ls[0] = ls[i];// i 位置的数据存入哨兵位，因为i位置会被后面的移动数据操作覆盖
            int j = i;
            while(ls[j-1] > ls[0]) // 不再判断j是否越界
            {
                ls[j] = ls[j-1];
                j--;
            }
            ls[j] = ls[0];
        }
    }
}
```

在一些查找操作中，有时候也会用到哨兵位

比如要查找某个值，可以在表中适当的位置预置一个等于这个值的哨兵位，这样在查找过程中就不用考虑边界越界，也不用考虑找不到的情况，查找遍历的算法实现就可以很简洁，只需在查找结束的时候，判断一下结果是否是哨兵位，如果是哨兵位，则说明没有找到。　　

#### 巧用数组下标

数组的下标是一个隐含的很有用的属性，巧妙地使用这个属性，对简化算法实现有很大的帮助。

比如将阿拉伯数字转换成中文数字的算法，就使用了这种定义中文字符数组：

```其他
const char *chnNumChar[CHN_NUM_CHAR_COUNT] = { “零”, “一”, “二”, “三”, “四”, “五”, “六”, “七”, “八”, “九” };
```

利用数组下标只需一行代码就可找到阿拉伯数字对应的中文数字，比如数字 5 对应的中文数字就是：

```
const char *chn_five = chnNumChar[5];
```

在一些数字或词汇统计的算法中，有时候也可以利用数组下标巧妙地简化算法。

比如这个题目：已知数列由 n 个最大值不超过 32 的正整数组成，请统计一下数列中各个数字出现的次数。

既然数列中的每个数都不超过 32，不妨设置一个容量是 33 的数组，每个数组元素就是下标对应的那个数字的出现次数。

利用这个关系，只需一行代码就可以完成统计，不需要两次遍历数列做比较：

```C++
int count[33]={0};
for(int i = 0; i < n; i++)
{
    count[numbers[i]]++;
}
```

在某些情况下，问题域内的一些特殊数据元素，比如 ID、类型等标识性属性，如果能定义成从 0 开始的连续整数，也可以利用数组和数组下标的特殊关系，简化数据模型，优化代码结构。

比如后面第 3 部分介绍“爱因斯坦的思考题”解法时，就将房子颜色、国籍、饮料类型、宠物和香烟牌子作为类型属性，定义成从 0 开始的索引值（为保证可读性，定义成有意义的常量值）：

```c++
type_house = 0,
type_nation = 1,
type_drink = 2,
type_pet = 3,
type_cigaret = 4
```

然后将这五种类型属性定义成数组：

```C++
int itemValue[GROUPS_ITEMS];
```

现在要查看一个 GROUP 绑定组中房子的颜色是否是蓝色，就可以这样编写代码

```C++
if(group.itemValue[type_house] == COLOR_BLUE)
```

这样的例子应用得非常广泛，只要控制好数组越界问题，巧妙地设计数据结构，定义有意义的常量名称，可以在不影响代码可读性的基础上极大地简化算法实现。

#### 取余的用法

取余运算常用来判断是否能被另外一个数整除

由此引申而来可以判断一个数是偶数还是奇数

```c++
if ((number % 2) == 0)
 {
     //偶数
 }
 else
 {
     //奇数
 }
```

**须知，取余运算基本上还是一个除法运算，如果仅仅是判断奇偶数，判断（number & 1）是否等于 0 是更好的方法**。

更一般的情况，当取余运算的除数是 2 的 n 次方的时候，用 & 运算符代替取余会更高效。比如当 x=2^n 的时候，a % x 的结果与 a & (x - 1) 的结果是等价的。

计算机没有环形数据存储方式，只能用线性表模拟，类似这样的模拟环形数据结构中，取余运算也常常用于下标计算。

比如用数组模拟环形数组的情况，从任意位置开始遍历数组，当到达数组最后一个元素时，需要回绕的数据的第一个元素继续遍历，可以这样处理：

```c++
int elements[N];
int pos = x;// 遍历起始位置
for（int i = 0; i<N;i++)
{
    if(pos < N)
    {
        // 使用element[pos]
    }
    else
    {
        pos = 0; // 回绕到开始
        // 使用element[pos]
    }
    pos++;
}
```

如果对 pos 位置做取余操作，也可以起到同样的效果，而且循环结构内的代码可以简化

```c++
for (int i = 0; i < N; i++)
    {
        //使用element[pos]

        pos = (pos + 1) % N;
    }
```



#### 一重循环遍历二维数组

二维表的遍历一般需要两重循环来实现，但是两重循环的代码不如一重循环的代码清爽，很多情况下用一重循环遍历二维表也是一种不错的选择。

用一重循环遍历二维表关键是对下标的处理，对于一个 M × N 的二维表，可用以下方法解出对应的二维下标：

```c++
int row = i / M
int col = i % N
```

反过来，也可以用以下公式将二维坐标还原为一维坐标：

```c++
int i = row * N + col
```

很多九宫格类型的游戏棋盘的初始化就是用的这种方法。

```c++
for(int i = 0; i < 9;i++)
{
    int row = i/3;
    int col = i%3;
    game->cell[row][col].fixed = false;
}
```

#### 棋盘（迷宫）类算法方向遍历

棋盘或迷宫类游戏常常需要配合各种搜索算法，二维棋盘和迷宫的搜索常常是沿着与某个位置相临的 4 个或 8 个方向展开，对这些方向的遍历就是搜索算法的主要结构。

我常常看到一些朋友给出的算法用了长长的 if-else 或 switch-case 语句，无非是这样的结构：

```c++
switch(direction)
{
case UP:
……
case DOWN:
……
case LEFT:
……
case RIGHT:
……
}
```

![方向](.\方向.png)

观察每一个 case 分支，除了数组下标计算不同，其他代码都是雷同的重复代码，其实这种情况下最常用的方法是使用方向偏移数组，用一个循环对这个方向数组遍历一遍就可完成对各个方向的搜索。

以二维数组定义的棋盘为例，如果从 i 行 j 列开始向上、下、左、右四个方向搜索，则这四个方向可转换为以下行、列坐标关系：

- 向左搜索：行坐标 i 不变，列坐标 j-1
- 向上搜索：行坐标 i-1，列坐标不变
- 向右搜索：行坐标 i 不变，列坐标 j+1
- 向下搜索：行坐标 i+1，列坐标不变

根据以上关系，首先定义二维数组下标偏移量，然后定义一个偏移量数组，分别表示向四个方向的数组下标偏移量：

```c++
typedef struct 
{
   int x_off;
   int y_off;
}OFFSET;

OFFSET dir_offset[] = {{0,-1},{-1,0},{0,1},{1,0}};
```

假设当前位置的二维数组下标是 x、y，则对此位置开始向四个方向搜索的代码可以如此实现：

```c++
for(int i = 0; i < count_of(dir_offset); i++)
{
    int new_x = x + dir_offset[i].x_off;
    int new_y = y + dir_offset[i].y_off;
    ……
}
```

这种算法实现避免了对每个方向都进行下标计算，即便是增加两个斜线方向，从 4 个方向搜索扩展到 8 个方向搜索，只需调整`dir_offset`数组即可，摆脱了冗长的 switch-case 代码结构。

#### 单链表

单链表有很多有意思的问题，比如**“判断单链表是否有环”、“如何一次遍历就找到链表中间位置节点”、“单链表中倒数第 k 个节点”**等问题，

解决这三个问题需要使用双指针的技巧，比如第一个问题，设置一个“慢指针”和一个“快指针”，从链表头开始遍历，慢指针一次向后移动一个节点，快指针一次移动两个节点。如果链表没有环，则快指针会先到达最后一个节点（NULL），否则的话，快指针会追上慢指针（相遇）。

第二个问题同样设置一快一慢两个指针，慢指针一次移动一个节点，快指针一次移动两个节点，当快指针移动到结尾时，慢指针指向的就是中间节点。

第三个问题也是双指针，其中一个先移动 k 个节点，然后两个指针以相同的速度一起移动，当先移动的指针移动到结尾的时候，后移动的指针指向的就是倒数第 k 个节点。

单链表还有一个经常被面试到的题目，就是单链表逆序。

很多公司的面试题库中都有这道题，有的公司明确题目要求不能使用额外的节点存储空间，有的没有明确说明，

但是如果面试者使用了额外的节点存储空间做中转，会得到一个比较低的分数。

不使用额外存储节点的情况下使一个单链表的所有节点逆序可以采用递归的方法，也可以采用循环迭代的方法，这里我们只介绍递归的方式，因为这种方法比较容易理解，算法代码的实现也很简单。

![单链表逆转](.\单链表逆转.png)

递归方法的核心就是确定递归子问题

链表类的问题找递归子问题的方法基本固定，就是每次除去链表头部第一个节点，剩下的序列作为分解的子问题。

主要的算法实现思路是先将当前的表头节点从链表中拆出来，然后对剩余的节点组成的子链表进行逆序

最后将当前的表头节点连接到新链表的尾部

如图（2）所示，每一轮递归都是先对子链表逆序，然后将拆出来的 head 节点附加到新的子链表的尾部。虽然递归调用的顺序是从 a 到 c 的顺序，但是递归逆序的实际操作过程需要从 c 到 a 反着来理解。

图（2-c）就是递归符合退出条件时的状态，此时子链表只剩一个节点，直接返回这个节点作为子链表的 `new_head` 节点。随后的递归操作将子链表的 head 节点附加到`new_head`节点的尾部，如代码所示：

```c++
LINK_NODE * reverse_link(LINK_NODE *head)
{
    LINK_NODE *newHead;
    if((head == nullptr) || (head->next == nullptr))
        return head;
    
    newHead = reverse_link(head->next); // 递归逆序子链表部分
    head->next->next = head; // 回溯部分
    head->next = nullptr;
    
    return newHead;
}
```

这段代码的关键点是头节点 head 的下一个节点 head→next 将是逆序后的新链表的尾节点，也就是说，被摘除的头接点 head 需要被链接到 head→next 才能完成整个链表的逆序。

### 2-1 非线性方程与牛顿迭代法

#### 代数法求解低阶非线方程

用代数方法求一元非线性方程的解的方法有很多，常用的方法有开平方法、配方法、因式分解法、公式法等，近似求解的方法有作图法以及各种迭代法。

像开平方法、配方法和因式分解法这样的代数方法只适用于一些特殊的一元非线性方程，使用范围有限。

而公式法则只适用于低阶方程，

到目前为止，除了少数特殊形式的五阶一元非线性方程之外，五阶及五阶以上的非线性方程被认为是没有求解公式的。

代数法求解方程虽然准确性好、精度高，但是不利于编制计算机程序，所以在数值分析领域，常用各种迭代法求解一元非线性方程。

迭代法方法简单，适合计算机求解，甚至可以被固化到硬件芯片中，计算效率并不比代数法差。常用的求解一元非线性方程的方法有**二分逼近法和牛顿迭代法**，

这一课就分别介绍如何设计和实现这两种迭代法的程序代码。

#### 二分逼近法

##### 原理

对于实数域的函数 f(x)，如果存在实数 k，使得 f(k) = 0，则 x = k 就是函数 f(x) 的零点。

如果函数 f(x) 是连续函数，且在区间 [a,b] 上是单调函数，只要 f(a)和 f(b) 异号，就说明在区间 [a,b] 内一定有零点，此时就可以使用二分逼近法近似地找到这个零点。

假设在上述区间上，f(a) < 0，f(b) > 0，则可按照以下过程实施二分逼近法：

(1)如果 f((a+b)/2) = 0，则 (a+b)/2 就是零点；

(2)如果 f(a)⋅f((a+b)/2)<0，则零点在区间 [a,(a+b)/2] 上，令 b = (a+b)/2，继续从第(1)步开始判断；

(3)如果 f(a)⋅f((a+b)/2)>0，则零点在区间 [(a+b)/2,b] 上，令 a = (a+b)/2，继续从第(1)步开始判断。

从上述过程可以看到，每次运算之后，区间范围就缩小一半，呈现线性收敛速度。由以上分析可知，数学意义上的二分逼近法可以采用迭代法的思想设计算法实现。

##### 实现

回忆一下我们在基础部分讲的迭代法的三个要点，它们分别是迭代变量、迭代递推关系公式和迭代终止条件。

首先确定迭代变量，迭代变量是由迭代关系式确定的。一般情况下，迭代变量就是计算结果 x，但是二分逼近法的迭代关系式不是计算结果 x 的迭代关系，而是逼近区间 [a, b] 的关系，所以这个算法的迭代变量就是表示区间范围的 a 和 b 两个变量。

接下来是确定迭代递推关系，其递推关系公式就是前面描述的实施过程中的(2)和(3)两步给出的 a 和 b 两个量的递推更新计算方法，即：

![二分逼近法](.\二分逼近法.png)

最后是迭代退出条件，退出条件其实就是：f((a+b)/2)=0。

但是因为浮点数精度很高，在计算机系统中直接按照 f((a+b)/2)=0 判断是很难的，有时候进行很多次迭代也无法满足这个条件，更何况由于数据存储方式的原因，计算机无法对两个浮点数直接做相等的判断，通常只要 f((a+b)/2)在精度允许的范围内逼近 0 时就可以结束二分逼近过程，将 (a+b)/2 作为零点，在精度和计算速度二者之间取折中。

除了判断 f((a+b)/2) 的值，还可以根据区间 [a, b][a,b] 的大小确定结束条件，在精度允许的范围内，只要区间范围小于精度阈值，也可以直接取 (a+b)/2 作为零点。确定以上三个条件，用迭代法实现二分逼近法求解一元高次方式的算法实现就很简单了：

```c++
const double PRECISION = 0.00000001;
typedef double (*FunctionPtr)(double);
double DichotomyEquation(double a, double b, FunctionPtr f)
{
    double mid = (a+b)/2.0;
    while((b-a) > PRECISION)
    {
        if(f(a) * f(mid) < 0.0)
        {
            b = mid;
        }
        else
        {
            a = mid;
        }
        
        mid = (a+b) /2.0;
    }
    
    return mid;
}

// 对于特定区间的一个函数
double func(double x)
{
    return (2.0*x*x + 3.2*x -1.8);
}
```

二分法的局限性就是**不能计算复根和重根**，需要借助其手段确定零点所在区间。

设方程为 f(x) = 2x^2 + 3.2x - 1.8，求根精度是 PRECISION = 0.000000001，在 [-0.8,8.0] 区间上求解 x= 0.440967364，while 循环共做了 34 次循环迭代。

除了求解非线性方程，二分逼近法还可以用来求解平方根（或 n 次方根），对于 x^2 =n，只需将其转化为方程 f(x) = x^2 - n，就可以将求平方根转化成求这个方程的解。同样的道理，我们下面要介绍的牛顿迭代法也可以做类似的事情。

#### 牛顿迭代法

牛顿迭代法又称为牛顿－拉弗森方法（Newton-Raphson Method），它是一种在实数域和复数域上近似求解方程的方法。

既然是迭代法，那么牛顿迭代法的算法实现肯定适合用迭代法模式。

![牛顿迭代法](.\牛顿迭代法.png)

牛顿迭代法使用函数 f(x) 的泰勒级数的前面几项来寻找方程 f(x) = 0 的根，先介绍一下牛顿迭代法的原理。首先，选择一个接近函数 f(x) 零点的 x0 作为迭代初始值，计算相应的 f(x0) 和切线斜率 f′(x0) (这里 f′(x) 是函数 f(x) 的一阶导函数）。然后我们经过点 (x0，f(x0)) 做一条斜率为 f′(x0) 的直线，该直线与 x 轴有一个交点，可通过以下方程的求解得到这个交点的 x 坐标：

![公式](.\公式.png)

求解这个方程得到：

![公式2](.\公式2.png)

我们将新求得的点的 xx 坐标命名为 x1，通常 x1 会比 x0 更接近方程 f(x)=0 的解。因此我们现在可以利用 x1 开始下一轮迭代。根据上述方程中 x1 和 x0 的关系，可以得到一个求解 x 的迭代公式：

![8](.\8.png)

这就是牛顿迭代公式。目前已经证明，如果f(x) 的一阶导函数 f′(x) 是连续函数，并且待求的零点 x是孤立的，则在零点 x 周围存在一个区间，只要初始值 f′(x0) 位于这个区间，牛顿法迭代必定收敛。并且，只要 f'(x)≠0，牛顿迭代法将具有平方收敛的性能。这意味着每迭代一次，结果的有效数字将增加一倍，这比二分逼近法的线性收敛速度**快了一个数量级**。

##### 导函数的求解与近似公式  

牛顿迭代公式中需要计算函数的导数，直接根据原函数推出一阶导函数，然后计算导函数的值有点困难，一般都是利用导数的数学原理，使用近似公式直接求函数在某一点的导数。

导数的数学定义是：当函数 y=f(x) 的自变量 x 在一点 x0 上产生一个增量 Δx 时，函数输出值的增量 Δy 与自变量增量 Δx 的比值在 Δx趋于 0 时的极限值。如果这个极限值存在，则这个值就是 f(x) 在 x0 处的导数，记做 f′(x0)。用公式定义即为：

极限是在无穷小或无穷大的尺度上考察函数的一些特性，在计算机上无法表达无穷小和无穷大，只能在数据能表达的合法范围内，在满足计算精度的情况下通过最小值来近似模拟。

如果无法精确计算导数 f′(x0)，我们仍然采用近似计算方法得到一个满足精度的模拟值。根据导数的数学定义，如果不考虑极限，这个值就是 Δy/Δx 的值，在 x0 附近一个非常小的尺度上选择 Δ，可以得到近似的导数值。我们选择按照以下近似公式计算导数值：

![6](.\6.png)

##### 算法实现

根据牛顿迭代法的迭代关系公式，牛顿迭代法的迭代变量就是要求的结果 x ，迭代的初始值可以选择一个比较接近近似解的值，对于单调区间来说，这个值可以是任意值，甚至可以是区间边界值，

迭代递推关系就是上面数学原理部分给出的迭代公式，

迭代终止条件就是找到一个精度符合要求的近似解。

判断迭代变量是否就是符合精度的解的方法就是计算最近两个迭代的值，看其差值是否小于迭代精度差值的要求。根据迭代递推关系，用循环实现迭代递推最简单。设计算法时，为了防止因为迭代不收敛导致的死循环，一般还可以增加一个迭代退出条件，即设置一个迭代次数上限。

```c++
double NewtonRaphson(FunctionPtr f,double x0)
{
    double x = INVALID_VALUE;
    int count = 0;
    do
    {
        double x1 = x0 -f(x0)/CalcDerivative(f,x0);
        if(fabs(x1-x0) < PRECISION)
        {
            x = x1;
            break;
        }
        x0 = x1;
        count++;
	}while(count<MAX_RUN_LOOP);
    return x;
}
```

参数 x0 是迭代初始值。选择与上面相同的例子函数，并将迭代初始值设置为区间最大值 8.0，使用牛顿迭代法也只需要 7 次迭代，就可以得到和二分逼近法精度一样的近似解。

选择初始值 -8.0 从另一个方向计算，还可以得到另一个解 x = -2.040967365，计算这个解也只需要 6 次迭代，可见牛顿迭代法的收敛速度是超线性的。



### 2-2 线性方程组的求解

多元一次方程组，又称为线性代数方程组。

在数值分析领域里有很多算法都会用到线性代数方程组的求解，比如三次样条曲线拟合时用到的插值算法。

求解线性代数方程组可以用高斯消元法。高斯消元法是一种代数的方法，其主要思想是通过对系数矩阵进行行变换，将方程组的系数矩阵由对称矩阵变为三角矩阵，从而达到消元的目的，最后通过回代逐个获得方程组的解。这和手工求解多元一次线性方程组的解题思想是一致的，类似于各种公式法求解方程的方式。

这一课我们介绍两种常用的迭代法求解方程组，分别是雅可比迭代法（Jacobi）和高斯—赛德尔迭代法（Gauss—Seidel）。

迭代法不仅可以求解线性方程组，还可以求解非线性方程组，并且迭代法的算法实现简单，便于用硬件逻辑实现，在数值分析领域得到了广泛的应用。

通过这两种迭代法的算法实现过程，大家可以进一步理解迭代法的本质。



#### 雅可比迭代法

雅可比迭代法以普鲁士著名数学家雅可比的名字命名，其原理很简单，迭代计算公式也很简单。

雅可比迭代法只需计算一次矩阵和向量的乘法，且计算过程中原始矩阵 A 保持不变，便于用多线程并行计算的方式优化效率。对于 n 阶线性方程组 Ax=b，假如其系数矩阵 A 是非奇异矩阵，且对角线元素非 0，就可以证明雅可比迭代过程是收敛的。

先来看看雅可比迭代法迭代关系式的推导过程，对于 n 阶方程组：

![QQ截图20190531233901](.\QQ截图20190531233901.png)

沿对角线依次选取x1,x2,...xn，将其他项都移到等式的右边（变符号的项就是移动到等式右边的项），然后等式两边分别除以x1,x2,...xn 对应的系数a11,a22,...ann，将方程组变形为：

![QQ截图20190531234127](.\QQ截图20190531234127.png)

以此关系可得到其迭代关系式为：

![QQ截图20190531234345](.\QQ截图20190531234345.png)

任选一组初始值：

![QQ截图20190531234602](.\QQ截图20190531234602.png)



带入迭代关系式，即可启动迭代运算，直到获得符合精度要求的解。

重要的事情要说 n 遍：迭代法算法实现三要素是迭代变量、迭代递推关系式和迭代终止条件。

2-1 课我们介绍的非线性方程求解，迭代变量一般是一个，二分逼近用了两个迭代变量，也仅仅是两个，但是这一课，我们说的是方程组。

对于方程组问题，迭代变量显然就是 n 个 x 的未知数：

x1,x2,...,xn

一般来说，我们需要一个数组 x[n] 来表示迭代变量。

迭代递推关系是就是上图给出的迭代关系公式，n 个迭代关系公式，一个都不少。

相比一个迭代变量的情况，n 个迭代变量的退出条件稍微复杂一些，需要 n 个迭代变量中的每一个的值都要符合精度要求。

但是对于每一个迭代变量 xi 来说，只要其两次迭代的差值小于预先定义的精度值，即可认为未知数 xi 的解已经满足精度要求，这也是很多迭代法求解方程时常用的退出条件。

求解所需要的条件有两个，**一个是原方程组等号左边的系数矩阵 A，另一个是等号右边的结果向量 b**。

算法的输出是向量 x，存放所有未知数的解，一般情况下，都会在迭代开始时将向量 x 初始化成迭代初始值，计算结束后，向量 x 中的值就是求解的结果。

从数据模型方面考虑，这种方程组问题通常都会用二维数组来描述系数矩阵，用一维数组存放原方程组的向量 b，再用一个数组存放既是解又是初始值的向量 x。

算法实现上，因为需要一个循环处理每个迭代变量的递推计算，所以算法的整体结构应该是一个 2 重循环，外层循环确定迭代递推是否得到全部符合精度的解，内层循环计算每一个未知数 x 的迭代关系式，有 n 个方程就需要循环 n 次。根据以上分析，算法程序的主体结构大致就是这个样子：

```c++
void jacobi_eqn(double a[][], double b[], int n, double x[])
{
    double xt[VEC_N];
    do
    {
        for(int i = 0; i<n; i++)
        {
            xt[i] = x[i]...... //根据关系计算xi的新值
        }
        
        for(int j = 0; j<n; j++)
        {
            x[i] = xt[i]; // 更新x，准备下一次迭代
        }
    }while(所有x[i]精度符合要求);
}
```

在这个框架中，首先补充 xt[i] 的计算，根据迭代关系公式，这部分的计算非常简单：

```c++
double sum = 0.0;
for(int k = 0; k<n; k++)
{
    if(i != k)  // 对角线元素不计算
    {
        sum += a[i][k] * x[k];
    }
}
xt[i] = (b[i]-sum) / a[i][i]; // 根据关系计算xi的新值
```

接下来补充循环退出条件，当所有解的迭代差值小于预定的精度值时，就可以退出迭代。我们用一个独立的函数 calc_max_diff() 来计算每个未知数的迭代差值，并得到其中差值最大的那个：

```c++
double calc_max_diff(double xt[],double x[],int n)
{
    double max_diff = std::fabs(xt[0]-x[i]);
    for(int i = 1; i<n; i++)
    {
        double diff = std::fabs(xt[i]-x[i]);
        if(diff > max_diff)
        {
            max_diff = diff;
        }
    }
    
    return max_diff;
}
```

需要注意的是，计算迭代差值要在最后更新 x 的操作之前进行，只要得到的 max_diff 大于预定的精度，迭代就要继续。最后完整的雅可比迭代算法实现如下：

```c++
const double PRECISION = 0.000000001;
const int VEC_N = 16;  //实际方程组的个数 n 必须小于VEC_N

void jacobi_eqn(double a[][VEC_N], double b[], int n, double x[])
{
    double xt[VEC_N];
    double max_diff = 0.0;

    do
    {
        for (int i = 0; i < n; i++)
        {
            double sum = 0.0;
            for (int k = 0; k < n; k++)
            {
                if (i != k)  //对角线元素不计算
                {
                    sum += a[i][k] * x[k];
                }
            }
            xt[i] = (b[i] - sum) / a[i][i];   //根据关系计算 xi 的新值
        }

        max_diff = calc_max_diff(xt, x, n);

        for (int j = 0; j < n; j++)
        {
            x[j] = xt[j]; //更新 x，准备下一次迭代
        }
    } while (max_diff > PRECISION);
}
```

雅可比迭代原理和算法实现都很简单，但是雅可比迭代存在收敛速度慢的问题，以下面的方程组为例，求得满足精度要求 0.000000001 的解（x=-4、y = 3、z = 2），需要进行 33 轮迭代计算。工程中一般不直接使用雅可比迭代法，而是使用各种基于雅可比迭代法的改进方法。

5x+2y+z=-12

-x+4y+2z=20

2x-3y+10z=3



#### 高斯-赛德尔迭代法

雅可比迭代法每次迭代计算时，将上一次的迭代变量整体带入到迭代关系式中，计算新的迭代变量值，也就是所谓的整体迭代。

在迭代收敛的前提下，如果迭代变量中的每个分量 x 在计算出新的迭代值后，直接带入迭代，参与其他迭代分量的计算，则能显著地提高迭代效果，这种改进的方法就是高斯-赛德尔迭代法。

从算法实现的角度理解，这种改进思想就是每计算出一个迭代分量的新迭代值，就立即让它参与到其他迭代分量的计算中，其迭代关系可以理解为：

![QQ截图20190601001658](.\QQ截图20190601001658.png)

高斯-赛德尔迭代法的算法实现比雅可比迭代法还要简单一点，x[i] 直接计算直接用，不需要 xt 数组存储新的迭代分量。

我们可以在 jacobi_eqn() 函数的基础上修改实现高斯-赛德尔迭代算法，因为没有 xt 数组存放整批的迭代分量新值，所以用于判断迭代退出条件的 max_diff 就不能一次性整体计算出来，只能一个分量一个分量地计算，也就是把 calc_max_diff() 函数的内容拆出来，放到迭代循环中逐次计算。

```c++
const double PRECISION = 0.000000001;
const int VEC_N = 16;  //实际方程组的个数 n 必须小于 VEC_N

void gauss_seidel_eqn(double a[][VEC_N], double b[], int n, double x[])
{
    double max_diff = 0.0;

    do
    {
        max_diff = 0.0;
        for (int i = 0; i < n; i++)
        {
            double sum = 0.0;
            for (int k = 0; k < n; k++)
            {
                if (i != k)  //对角线元素不计算
                {
                    sum += a[i][k] * x[k];
                }
            }
            double xt = (b[i] - sum) / a[i][i];   //根据关系计算 xi 的新值
            if (std::fabs(xt - x[i]) > max_diff) //max_diff 只保留差值最大的
            {
                max_diff = std::fabs(xt - x[i]);
            }
            x[i] = xt;
        }
    } while (max_diff > PRECISION);
}
```



### 2-3 迭代法计算定积分

这一课我们介绍两种计算数值积分的常用算法，分别是变步长梯形公式法和变步长辛普森公式法。

首先从梯形公式入手来推导出复合梯形公式法，在实现复合梯形公式法的基础上，再实现变步长梯形公式法。同样，变步长辛普森公式法也是从辛普森公式入手的，首先实现复合辛普森公式法的算法，然后再实现变步长辛普森公式法。

这两种变步长的方法都是使用了迭代法的思想，但是和之前几课中介绍的迭代法略有不同。之前介绍的牛顿迭代法、雅可比迭代法和高斯—赛德尔迭代法都是通过迭代关系式来实现新值和旧值的更替。

这一课介绍的两个算法没有迭代关系式，它是通过控制计算范围的变化来获得迭代自变量的值，用直接替换的方法来实现新值和旧值的更替，因此在构造算法实现的方法上也有差异

#### 梯形公式法

假设被积函数为 f(x)f(x)，积分区间为 [a,b]，根据定积分的几何意义，定积分就是求函数 f(x) 在区间 [a,b] 中曲线下包围的面积。

在数值分析领域中，通常用梯形公式法近似计算定积分。如图（1）所示，用计算曲线内接梯形面积的方法来近似计算定积分，梯形公式可定义为：

![QQ截图20190601002158](.\QQ截图20190601002158.png)

#### 复合梯形公式法

用梯形公式计算定积分，当区间 [a,b] 比较大的时候，其误差也会大到无法接受。

如果将大的区间分割成 n 个小的区间，对每个小区间应用梯形公式计算内接梯形面积，然后再将所有小梯形的面积求和得到结果，误差则会大大的缩小，这就是复合梯形公式法。

这样分割以后，每个小区间的长度被称为“步长”，即 step=(b-a)/n。积分区间分割得越细，梯形公式法得到的近似值就越逼近真实值。

复合梯形公式法的计算公式如下：

![QQ截图20190601002327](.\QQ截图20190601002327.png)

直接利用复合梯形公式计算定积分的方法就是复合梯形公式法，复合梯形公式法的算法实现非常简单，就是把此公式翻译成代码即可。为了提高算法的效率，我们把第 2-2 课中的公式做个变形处理：

![QQ截图20190601002518](.\QQ截图20190601002518.png)

算法实现如 trapezium() 函数所示，其定积分的精度取决于区间划分个数 n:

```C++
double trapezium(std::function<double(double)> func, double a ,double b, int n)
{
    double step = (b-a) / n;
    double sum = (func(a) + func(b)) /2.0;
    
    for(int j = 1;j<n;j++)
    {
        double xj = a+j*step;
        sum = sum + fun(xj);
    }
    
    sum *= step;
    return sum;
}
```



#### 变步长梯形公式法

复合梯形公式法的算法原理和实现都很简单，但是**复合梯形公式法的问题在于步长控制比较困难，无法确定 n 的取值是多少才能得到符合精度的解**。

为了提高迭代计算的效率，人们想出了一种利用迭代思想的变步长梯形公式法。在对定积分图形的内接梯形分割的时候，每个迭代都把上一个迭代分割的梯形再平均分割成两个小梯形。

随着迭代次数增加，逐步增加梯形分割的个数，使得梯形分割沿积分自变量方向的步长由粗到细，逐步变化，就是所谓的变步长。每个迭代计算一次小梯形面积的和，并与上个迭代计算的小梯形面积的和做比较，若相邻两次迭代的差值达到精度要求，则退出迭代计算，否则就对当前的所有小梯形继续分割，进行下次迭代计算。

如图（2）所示，每次分割得到的两个小梯形的面积之和都比分割前的大梯形面积更接近曲线的积分值。

![QQ截图20190601003059](.\QQ截图20190601003059.png)

根据上述的变步长梯形公式法原理，我们来考虑如何用迭代法设计对应的算法实现。

首先回忆一下迭代法的三个要点，也就是迭代变量、迭代关系式和迭代终止条件（迭代控制）。

对于这个问题，迭代变量就是每次梯形分割后的小梯形面积之和，

迭代关系则非常简单，就是用本迭代的迭代自变量代替上个迭代的迭代自变量的值，

迭代终止条件就是两个迭代的迭代自变量之差小于精度值。

迭代自变量的初始值就是最大的梯形面积，可由梯形面积公式直接计算出来。用一个变量 n 表示当前迭代分割小梯形的个数，n 的值每个迭代增加一倍

而每次分割后的小梯形面积和的计算可由第 2-2 课中给出的复合梯形公式算法 trapezium() 函数计算，迭代算法的整体结构是一个 do…while() 循环（大部分迭代法的算法实现都是循环结构）。

```c++
double vs_trapezium(std::function<double(double)> func, double a,double b)
{
    int n = 1; // 初始是一个大梯形
    double t1 = (b-a)*(fun(a) + fun(b))/2.0;
    double diff = eps + 1.0;
    do
    {
        n = 2*n;
        double t = trapezium(func,a,b,n); // 用复合梯形公式法计算n个小梯形的面积之后
        diff = std::fabs(t1-t); // 计算两次迭代的结果差值
        t1 = t;
    }while(diff >= eps);
    return t1;
}
```



#### 辛普森公式法

辛普森（Simpson）公式是牛顿—科特斯公式当 n=2 时的情形，也称为三点公式。

如图（3）所示，对于积分区间 [a,b]，选择中间 (a + b) / 2 的位置与 a 和 b 组成三个点进行插值计算，得到辛普森积分公式：

![QQ截图20190601174313](.\QQ截图20190601174313.png)

虽然比梯形公式好一点，但是当区间 [a,b] 比较大的时候，辛普森公式的误差仍然无法接受。

将复合梯形公式法的处理思想应用到辛普森公式中，这就是复合辛普森公式法。

同样将区间 [a,b] 平均分为 n 个小区间，每个小区间的步长 step=(b-a)/n。对于每个小区间 [xi−1,xi]，中心点位置为 xi-½，复合辛普森公式法的计算公式如下：

![QQ截图20190601175139](.\QQ截图20190601175139.png)

```c++
double simpson(std::function<double(double)> func, double a, double b, int n)
{
    double s1, s2;
    int i;

    double step = (b - a) / n;
    s1 = s2 = 0;
    for (i = 1; i < n; i++)
    {
        s2 += func(a + step * i);   //xi 求和
    }
    for (i = 1; i <= n; i++)
    {
        s1 += func(a + step * i - step / 2);  //(xi - step/2)求和
    }

    double s = step * (func(a) + func(b) + 4 * s1 + 2 * s2) / 6.0;

    return s;
}
```

#### 可变长辛普森公式法

和梯形公式一样，复合辛普森公式也可以改造为变步长辛普森公式法。

改造的方法就是使用迭代法的思想，通过改变区间个数 n 使得步长 step 也跟着变化，当迭代差值符合精度要求时即可停止迭代。算法的迭代变量仍然是每次分割后的小区间上使用辛普森公式计算的插值曲线面积之和，迭代关系则非常简单，就是用本迭代的迭代变量代替上个迭代的迭代自变量的值，迭代终止条件就是两个迭代的迭代变量之差小于精度值。

迭代变量的初始值就是在区间 [a,b] 上应用辛普森公式计算最大的区间面积。用一个变量 n 表示当前迭代分割小梯形的个数，n 的值每个迭代增加一倍。而每次分割后的小区间面积和的计算可由第 2-2 课中给出的复合辛普森公式算法 simpson() 函数计算，迭代算法的整体结构与变步长梯形法类似。

```c++
double vs_simpson(std::function<double(double)> func, double a, double b, double eps)
{
    int n = 1;   //初始分割一个大梯形
    double s1 = (b - a) * (func(a) + func(b) + 4 * func((a + b) / 2.0)) / 6.0; //计算初始梯形的面积
    double diff = eps + 1.0;
    do
    {
        n = 2 * n;    //梯形分割加倍
        double t = simpson(func, a, b, n); //用复合辛普森公式计算 n 个小梯形的面积之和
        diff = std::fabs(s1 - t);      //计算两次迭代的结果差值
        s1 = t; //更新迭代变量
    } while (diff >= eps);

    return s1;
}
```



### 3-1 装配线与工作站问题

首先介绍一下这个题目：Colonel 汽车公司在有两条装配线的工厂内生产汽车，一个汽车底盘在进入每一条装配线后，每个工作站会在汽车底盘上安装不同的部件，最后完成的汽车从装配线的末端离开，如图（1）所示：

![zhuanpeixian](.\zhuanpeixian.png)

每一条装配线上有 n 个工作站，编号为 j=1,2,…,n，把装配线 i（i 为 1 或 2）的第 j 个工作站表示为 S(i,j)。装配线 1 的第 j 个工作站 S(1,j) 和装配线 2 的第 j 个工作站 S(2,j) 执行相同的功能，然而这些工作站是在不同的时间建造的，并且采用了不同的技术，因此，每个工作站上完成装配所需要的时间也不相同，即使是在两条装配线相同位置的工作站也是这样。把每个工作站上所需要的装配时间记为 a(i,j)，并且，底盘进入装配线 i 需要的时间为 e(i)，离开装配线 i 需要的时间是 x(i)。正常情况下，底盘从一条装配线的上一个工作站移到下一个工作站所花费的时间可以忽略，但是偶尔也会将未完成的底盘从一条装配线的一个工作站移到另一条装配线的下一个工作站，比如遇到紧急订单的时候。假设将已经通过工作站 S(i,j) 的底盘从装配线 i 移走所花费的时间为 t(i,j)，现在的问题是要确定在装配线 1 内选择哪些工作站以及在装配线 2 内选择哪些工作站，可以使汽车通过工厂的总时间最小，如图（2）所示，最快的时间是选择装配线1的 1、3 和 6 号工作站以及装配线 2 的 2、4 和 5 号工作站。

![装2](.\装2.png)

这个题目的意思就是汽车底盘选择一条装配线，期间不能更换，从第一个工作站移动到最后一个工作站，即可完成安装，但是根据对题目的理解，这样所花费的时间肯定不是最短的。

如果另一条装配线上的某个工作站效率比较高，那么装配到这一步的时候，换到那条装配线上进行装配肯定会节省时间，但是考虑到从一条装配线移动到另一条装配线也需要花费时间，那就要综合考虑了。

“移”还是“不移”？这是个问题。

之前的课程介绍过穷举的几种模式，这里复习一下，这些模式分别是线性遍历、广度搜索遍历和深度搜索遍历以及树形遍历，具体使用何种遍历模式，取决于问题的解空间是什么模式。

本题的答案是汽车底盘完成安装花费的时间，不过千万不要头脑简单，本题的解空间肯定不是一个个装配时间。

透过现象看本质，装配时间是怎么算出来的？是汽车底盘在每个工作站之间移来移去，最后完成装配时把每次移动底盘需要的时间和在每个工作站的装配时间求和就是最终的装配时间。

所以，本题的**解空间是底盘在各个工作站上装配和移动的过程记录**，根据这个过程记录，很容易计算出实际的装配时间。

如何产生一个移动过程记录？

对了，产生一个移动过程记录的关键点是“移动”这个动作。

根据题意，每次“移动”会有两个可能的结果，其一是在本生产线上继续移动到下一个工作站，另一个是移动到另一条装配线上的下一个工作站。

显然，我们的移动过程记录是树形结构，每次移动产生两个分支

如图（3）所示，最终的结果就是和一棵二叉树一样的结构，从根节点到任何一个叶子节点就是一个移动过程。

我们的穷举过程就是对每个移动过程来计算花费的时间，然后比较时间，找出花费时间最短的移动过程。

![树形遍历](.\树形遍历.png)

对树形空间遍历，最好的策略就是使用递归的方法进行穷举。

考虑到解空间规模比较大，如果采用先穷举搜索得到全部的解空间，然后再逐个计算装配时间并比较时间的方法，就需要一个很大的存储空间，当问题规模比较大时，有可能超出系统存储能力的限制。

为了避免这个问题，算法在遍历的过程中，应该找到一个完整的装配过程后就立即与当前已知最小值进行比较，如果这个结果已经不是最优解，则不存储当前结果，然后回溯到上一个位置，继续遍历。

如果这个结果比当前最小值还要小，则记录这个结果，并更新当前已知最小值，然后再回溯。

#### 准备数据模型

根据题目给出的信息，这个算法给出的时间开销参数有四种，分别是每个工作站的装配时间、每个工作站转移到另一条装配线的转移时间、进入装配线时间和离开装配线时间

这些值统一存放在`Program_T`数据结构中。进入和离开装配线的时间开销用一维数组存储，每个工作站的装配时间和转移时间用二维数组存储，这个数据结构的定义比较简单：

```c++
typedef struct
{
    int assemble_time[LINES][STATIONS];
    int transport_time[LINES][STATIONS];
    itn enter_time[LINES];
    int exit_time[LINES];
}Program_T;
```

前面算法策略提到，穷举遍历不保存全部结果，但是需要保存当前正在搜索的一个结果和当前已知的最优结果。

根据题目要求，算法的结果输出除了装配时间，还要包含底盘在各个工作站的转移记录。

所以，每个结果应包含两个属性，一个是装配时间，另一个是转移记录。遍历结果的数据结构定义如下：

```c++
typedef struct
{
    int line[STATIONS]; // 遍历过程中的当前结果记录
    int fs;
    int fline[STATIONS]; // 当前已知的最优结果
    int ffs;
}Result_T;
```

转移记录用一个一维数组表示，表示每个工作站所在的装配线，比如 line[3] 存放的就是第 4 个工作站所在的装配线（工作站和装配线的编号都是从 0 开始，便于数组操作）。

ffs 和 fline 存放当前已知的最优结果，当整个搜索遍历完成后，它们就是最终结果。

#### 穷举算法设计

有递归的地方就有回溯，二者的关系剪不断，但理起来也不乱。

在上面“算法分析”中提到过，树形结构的遍历使用递归法最简单，

用递归法设计算法的关键是找到递归主体和递归退出条件，递归主体可以认为是一个子结构，所有的子结构都可以用同一套方法进行处理，子结构的区别仅仅在于层次或位置不同。

递归不能无限制进行，必须在合适的地方退出，以便进行回溯处理。

设计递归算法，递归主体和退出条件明确了，算法也就实现了。

先来分析一下这个算法的递归主体，这个算法实现的核心就是将汽车底盘从一个工作站移动到下一个工作站，移动底盘到下一个工作站有两种选择，归纳起来就是，假如底盘当前的位置在第 i 条装配线上的第 j 个工作站，则底盘可以采用以下两种方式移动：

- 移动到第 i 条装配线上的第 j+1 个工作站；
- 移动到第 (i+1)%2 条装配线上的第 j+1 个工作站，需要记录转移装配线的开销。

其中，(i+1)%2 的意义就是当 i 是 0 的时候，转到 1 号装配线，当 i 是 1 的时候，转到 0 号装配线）。

这就是我们的递归子结构，无论当前底盘在哪个工作站，都可以用这个子结构对其进行移动操作。

再看子结构之间的区别，那就是表示装配线和工作站编号的 i 和 j 两个参数。

如果算法的递归主体用一个接口函数来封装，那么这个函数至少要有 i 和 j 两个参数，考虑到程序参数和结果的传递，可以推导出递归算法的主体函数原型应该是这样的：

```c++
void search_stations_sequence(Result_t *rt,Program_T *para,int line,int station)
```

接着分析递归的终止条件。显然，当底盘从任何一条装配线的最后一个工作站移出时，即表示完成了汽车底盘的安装，也就意味着已经遍历到了一个结果。

根据对递归子结构的分析，当第 j 个工作站就是最后一个工作站时，就应该退出递归，开始回溯。

如果我们定义工作站的数量是 STATIONS，那么上述函数原型中 station 参数的值等于 STATIONS - 1 时，就意味着底盘已经完成最后一个工作站的安装，需要处理结果并进行回溯。

两个条件都已经分析完了，现在可以着手完成`search_stations_sequence()`函数的具体实现了。`search_stations_sequence()`函数应该做三个事情：

1. 当 station 参数等于 STATIONS - 1 时，处理结果并退出递归；
2. 将当前的装配线和工作站的编号记录到`Result_T`结果中；
3. 调整 line 和 station 参数，通过递归调用自身的方式，完成递归子结构中定义的操作。

将这三个事情翻译成代码，就是`search_stations_sequence()`函数的具体实现：

```c++
void search_stations_sequence(Result_T *rt, Program_T *para,int line, int station)
{
    if(station == (STATIONS-1)) // 1.完成装配，整理一次结果，退出当前递归子结构
    {
        rt->fs += para->assemble_time[line][station];
        rt->fs += para->exit_time[line];
        rt->line[station] = line;
        if(rt->fs < rt->ffs) // 当前穷举到的路径时间开销更小
        {
            rt->ffs = rt->fs;
            memmove(rt->fline,rt->line,STATIONS * sizeof(int));
        }
        return;
    }
    
    // 2. 记录中间结果到line属性中
    int curCost = rt->fs + para->assemble_time[line][station];
    rt->line[station] = line;
    
    // 3. 调整line 和station 参数，完成递归子结构的动作
    // 选样本装配线的下一个装配站，开销忽略不计
    rt->fs = curCost;
    search_stations_sequence(rt,para,line,station+1);
    
    /*选择另一条装配线的下一个装配站，需要计算转移开销*/
    rt->fs = curCost;
    rt->fs += para->transport_time[line][station+1];
    int nextline = (line + 1)%LINES；
    search_stations_sequence(rt,para,nextline,station+1);
}
```

当 station == (STATIONS - 1) 条件成立时，就意味着得到了一个结果，此时需要计算这次装配流程的时间开销。

由于 fs 参数已经记录了每一步的时间开销，所以这里只要加上最后一个工作站的装配时间和从装配线上移走需要的时间即可。

```c++
rt->line[station] = line;
```

这行代码的作用是记录最后一个工作站的装配线信息，形成完整的转移记录。

接下来就是与当前已知最优结果比较，当前已知最优结果被初始化为一个很大的数，这也是从一批结果中寻找最小值时常用的技巧。

最后是通过调整子结构参数递归调用`search_stations_sequence()`来遍历下一个工作站的所有移动操作，当完成后返回回溯点时，要对 fs 重新赋值，以实现正确的回溯。

最后，补上底盘进入装配线，开始穷举遍历的启动代码，算法就完成了。

```c++
reasult.fs = pd.enter_time[0]; // 装配线1的进入开销
search_stations_sequence(&result,&pd,0,0); // 从第一条装配线开始
result.fs = pd.enter_time[1]; // 装配线2的进入开销
search_stations_sequence(&result,&pd,1,0); // 从第二条装配线开始
```

只要`Program_T`的参数无误，就能得到正确的结果：

```c++
Total Time 38
Station 1 on Line 1
Station 2 on Line 2
Station 3 on Line 1
Station 4 on Line 2
Station 5 on Line 2
Station 6 on Line 1
```

使用穷举法实现了对“装配线和工作站”问题的算法设计，演示了如何用递归法对二叉树结构的解空间进行穷举遍历，重点介绍了数据模型的定义和算法实现的思考以及分析过程。

希望读者看完这一课的内容后，能够再掌握一种穷举遍历的方法，并且对穷举法有更深入的理解。



### 3-2 用三个水桶等分8升水的问题

有这样一个智力题目：

有三个分别是 3 升、5 升和 8 升容积的水桶，其中容积为 8 升的水桶中装满了水，容积为 3 升和容积为 5 升的水桶是空的，三个水桶都没有体积刻度。现在需要把大水桶中的 8 升水等分成两份，每份都是 4 升水，附加条件是只能使用这 8 升水和另外两个空水桶，不能借助其他容器或更多的水。

#### 问题分析

好莱坞电影《虎胆龙威 3》中，布鲁斯·威利斯饰演的纽约警探约翰·麦克莱恩被恐怖分子点名挑战，让他在指定的时间内完成各种危险指令，否则就威胁炸掉整个纽约市。

其中有一个情节就是在一个街心喷泉的边上放了一个容积为 3 加仑的水桶和一个容积为 5 加仑的水桶，让约翰在指定的时间倒腾出来 4 加仑的水，用 4 加仑的水的重量解除炸弹。

我们的英雄曾一阵手忙脚乱，不过最终解决了问题。

电影中的问题与本课的问题稍有差别，电影中只有两个水桶，但是水可以无限使用。

我们的题目有三个水桶，但是只能用 8 升水，不能用额外的水，当然也不能将水洒出来。

这个问题其实并不难，大部分人都可以在一分钟内给出答案，并且这个问题的答案也不止一个。最快的倒水操作如下所示，共需要 7 次倒水动作：

（1）从 8 升水桶中倒 5 升水到 5 升水桶中

（2）从 5 升水桶中倒 3 升水到 3 升水桶中

（3）从 3 升水桶中倒 3 升水到 8 升水桶中

（4）从 5 升水桶中倒 2 升水到 3 升水桶中

（5）从 8 升水桶中倒 5 升水到 5 升水桶中

（6）从 5 升水桶中倒 1 升水到 3 升水桶中

（7）从 3 升水桶中倒 3 升水到 8 升水桶中

那么问题来了，这个题目到底有多少种倒水的方法呢？水从水桶之间倒来倒去，情况太多了，一般人很难记得住这么多倒水动作的序列，但是计算机可以。

这不是一个典型意义上的求解最优解的问题，虽然可能暗含了求解倒水次数最少的方法的要求，但就本质而言，常用的求解最优解问题的高效的方法都不适用于此问题。

既然这个系列我们都在讲穷举法，这一课我们也用穷举法找出所有正确的倒水动作序列，我们不关心什么方法最快，当然，只要稍加改造，增加最短动作步骤数的判断，我们的算法还能找出最快的倒水动作序列。

#### 算法设计思路

既然要使用穷举法，首先来回忆一下使用穷举法设计算法的两个步骤：

- 确定问题的解（或状态）的定义，解空间的范围以及正确解的判定条件；
- 根据解空间的特点选择搜索策略，逐个检验解空间中的候选解是否正确，必要时可辅助一些剪枝算法，排除一些明显不可能是正确解的检验过程，提高穷举的效率。

接下来我们就从这两个步骤入手来介绍如何设计这个穷举算法。



#### 定义问题的状态

穷举法的关键是要确定解空间的范围和模式，然后才能确定以何种方法对解空间进行遍历。

要确定解空间，首先要定义问题的解。

虽然这个题目的要求是给出一组倒水动作的序列，这个动作序列最终能将 8 升水平分成两个 4 升水的状态，但是单纯考虑对动作的穷举是没有意义的，因为动作需要附加在某个状态上时才能产生结果。

现在换个思路，如果把某一时刻三个水桶中的水量视为一个状态，将倒水动作的变化转化为三个水桶中水的状态变化，则问题迎刃而解。

问题的解空间就是水桶状态的全部集合，正确解的判定条件就是容量为 8 升的水桶和容量为 5 升的水桶中各有 4 升水。

如果用一个三元组（或是三维向量）分别表示 8 升、5 升和 3 升水桶中的水量，则问题的初始状态就是 [8,0,0]，问题的解决状态就是 [4,4,0]。

求解这个问题的算法本质上就是对状态的穷举搜索，这样的状态变化搜索的结果通常是得到一棵状态搜索树，根节点是初始状态，叶子节点可能是最终状态，也可能是某个无法转换到最终状态的中间状态，状态树有多少个最终状态的叶子节点，就有多少种答案。

由此可知，解决本问题的算法关键是建立状态和动作的数据模型，并找到一种持续驱动动作产生的搜索方法。



#### 状态树和解空间

**倒水动作与静止状态的结合就产生了状态变化，持续的状态变化就产生了一棵状态树**，这个状态树上的所有状态就构成了穷举算法的解空间。

以初始状态 [8,0,0] 为例，如果与“1号桶倒 5 升水到 2 号桶”动作相结合，就得到了一个新状态 [3,5,0]，

同样，如果与“1号桶倒 3 升水到 3 号桶”动作相结合，就得到了另一个新状态 [5,0,3]。以此类推，

将**动作与状态枚举组合**后，可以得到如图（1）所示的状态树。

![QQ截图20190602155635](.\QQ截图20190602155635.png)

[8,0,0] 是状态树的根，图（1）只画出了这棵状态树的一部分，图中深颜色背景标识出的几个状态是状态树的一个分支，也是一个正确的解的状态转换路径。

根据题目的意图，最终的结果是要输出这条转换路径的倒水过程，实际上就是与状态转换路径相对应的动作路径，或动作列表（图（1）中蓝色文字描述的倒水动作序列）。

当定义了动作的数学模型后，就可以根据状态图中状态转换路径找到对应的动作列表，依次输出这个路径上每个状态对应的动作就可以得到一个完整的倒水过程。



#### 状态的数据模型

虽然我们定义的状态只有桶中的水量，但是考虑到桶中的水在变化的过程中，需要由桶的容积来确保状态的有效性（比如不能向一个 3 升的水桶倒 4 升水），

所以在设计数据结构时，我们以桶为单位，把容积和水量一起考虑，桶的数据模型如下：

```c++
class Bucket
{
    ……
    int m_water; // 当前水量
    int m _capicity; // 桶的容积
};
```

表示三个水桶的三维向量用数组表示，`std::vector<...>` 是 C++ 的数组，其类型就是前面定义的 Bucket。水的状态就是桶的状态：

```c++
class BucketsState
{
    ……
    std::vector<Bucket> m_buckets; // 桶的向量
    ACTION m_curAction; // 当前状态对应的动作
}
```

`m_curAction` 是当前状态绑定的倒水动作，即前一个状态通过这个倒水动作演变成当前状态，它并不是状态穷举过程中的关键属性，

记录这个状态对应的倒水动作的目的是为了能够在输出结果时，除了输出三个水桶的状态变化序列，还能够输出对应的倒水动作，使结果输出更有意思一点儿。



#### 倒水动作的数据模型

两个静态的水桶状态（BucketsState）是通过倒水动作建立关联的。

这里说的倒水动作必须是合法的倒水动作，因为水桶是没有体积刻度的，因此倒水动作也就不能是任意倒水行为

一个倒水动作合法的前提条件是原始的桶中有水且目的水桶中还有空间。

分析一下，实际上就两种情况：一种是目的水桶中的空间足够大，则原始桶中的水全部加到目的水桶中，此时原始桶成为空桶（水量变成 0）；另一种情况就是目的水桶中的空间不够大，只能倒入一部分水，此时原始桶中还剩有一部分水。

一个合法的倒水动作包含三个要素：原始桶编号、目的水桶的编号和倒水的量（体积）。

我们用一个三元组来描述倒水动作：{from,to,water}，from 是指原始桶的编号，to 是指目的水桶的编号，water 是此次倒水动作所倒的水量。

倒水动作的数据结构定义如下：

```c++
typedef struct
{
    int from;
    int to;
    int water;
}ACTION;
```

某一时刻三个水桶的状态，经过某个倒水动作后演变到一个新的状态，这是状态变化的过程。

根据 BucketsState 的定义，每当穷举遍历得到一个结果状态时，演变过程中的一些列状态和对应的倒水动作如图（2）所示：

![QQ截图20190602161035](.\QQ截图20190602161035.png)



#### 设计搜索算法

**状态树的遍历就是促使状态树上的一个状态向下一个状态转换的驱动过程，这是一个很重要的部分，如果不能正确地驱动状态变化，就不能实现这个穷举算法**。

上面提到的动作模型，就是驱动状态变化的关键因子。

对于一个状态来说，它能转换到哪些新状态，取决于它能应用哪些倒水动作，一个倒水动作能够在原状态的基础上“生成”一个新状态，不同的倒水动作可以“生成”不同的新状态。

由此可知，状态树遍历的关键是**找到三个水桶之间所有合法的倒水动作，用这些倒水动作分别“生成”各自相应的新状态**。

遍历三个水桶的所有可能倒水动作，就是对三个水桶任取两个进行全排列，这种排列的结果可以得到 6 种水桶的排列关系，《算法的乐趣》这本书中给的例子代码就是采用一个两重循环的结构组合出这 6 种倒水动作。

实际上，三个水桶就只有 6 个固定的倒水动作，分别是：1→2、1→3、2→1、2→3、3→1 和 3→2，我们可以用一个一维表来存储这 6 个动作，算法处理时直接遍历这个一维表就可以枚举全部倒水动作。

这和本课程基础部分介绍的方向遍历的思想类似，是一种一致性处理方法。

`std::pair<int, int>` 是一个整数对类型，其中 first 属性代表第一个整数，second 属性代表第二个整数，action_table 是由 `std::pair<int, int>` 类型组成的数组，注意代表水桶编号的数字已经调整为从 0 开始编号。

```c++
std;:vector<std::pair<int,int>> action_table = {{0,1},{0,2},{1, 0},{1, 2},{2, 0},{2, 1} };
for(const auto & act : action_table)
{
    BucketsState next;
    /*从 from 到 to 倒水，如果成功，next 返回倒水后的状态*/
    if(current.TakeAction(act.first,act.second,next))
    {
        ……
    }
}
```



#### 剪枝和优化（重复状态判断）

上面提到，采用深度优先搜索状态树，会遇到重复的状态而导致的状态环路。

比如，假设某一时刻从 1 号桶倒 3 升水到 3 号桶，下一个时刻又从 3 号桶倒 3 升水到 1 号桶，此时水桶的状态就又回到了之前的状态，这就形成了一个状态环路。

有时候状态环路可能复杂一点，几个状态之后才出现重复状态，图（1）就展示了一种复杂一点的状态环路。在状态 [3,5,0]→[3,2,3]→[6,2,0]→[3,5,0] 的转换过程中，[3,5,0] 状态再次出现形成状态环路

如果对这种情况不做处理，状态搜索就会在某个状态树分支陷入死循环，永远无法到达正确的结果状态。

除此之外，如果对一个状态树分支上的某个状态经过搜索，其结果已经知道，则在另一个状态树分支上搜索时再遇到这个状态时，可以直接给出结果，或跳过搜索，以便提高搜索算法的效率。

在这个过程中因重复出现被放弃或跳过的状态，可以理解为另一种形式的“剪枝”，可以使一次深度优先遍历很快收敛到初始状态，从图（1）可以看出来，这样重复出现的状态还是很普遍的情况。

考虑到上述两种情况，需要对当前深度遍历过程中经过的搜索路径上的所有已经搜索过的状态做一个记录，形成一个当前正在处理的状态序列表。

考虑到算法实现过程中，这个表要在其中的一端进行频繁的插入和删除操作，我们用一个 std::deque 来存储当前搜索的状态序列，states 初始化时只有一个初始状态节点：

```c++
std::deque<BucketsState> states;
BucketsState init = { { b_capicity[0], b_init[0] },
                      { b_capicity[1], b_init[1] },
                      { b_capicity[2], b_init[2] } };
states.push_back(init);
```

每次因为动作组合生成新状态时，都检查一下是否在这个记录中有状态相同的记录，如果存在状态相同的记录则跳过这个新状态，回溯到上一步继续处理下一个状态。

如果新状态是状态表中没有的状态，则将新状态加入到状态表，然后从新状态开始继续深度优先遍历。

```c++
if（!IsProcessedState(states,next))
{
    states.push_back(next);
    SearchState(states); // 从新的位置继续搜索
    states.pop_back();
}
```

#### 代码实现

至此，用穷举法设计倒水问题算法的分析全部完成，主要就是围绕穷举法的两个关键点展开的，这也是所有穷举算法设计分析的通用模式。

接下来的代码实现不需要过多文字，主要是结合具体代码来理解上述设计的方法如何实现具体的算法。

事实上，如果理解了上述算法分析过程，读者应该能够自己设计出来算法实现，不一定是用 C++，可以是其他编程语言；

同样，也不一定用本课例子代码中的方式定义数据结构，读者可以用自己惯用的方式定义数据结构。尽管如此，为了满足很多读者的好奇心，我在这里还是给出主体部分的代码实现。

#### 搜索算法代码

SearchState() 函数实现状态树的搜索遍历，是整个算法的核心。

SearchState() 函数每次都是处理 state 队列中最后加入的那个状态（通过 states.back() 得到），将其视为当前状态。

对这个当前状态的处理由两部分内容组成：第一部分 IsFinalState() 函数判断当前状态序列中最后一个状态是否就是最终结果状态，如果是就输出一组状态序列（以及对应的倒水动作）；

如果当前状态序列中最后一个状态不是结果状态，则转入第二部分开始搜索新的状态。搜索新状态的方法是遍历 action_table 表，尝试从 first 指定的水桶向 second 指定的水桶倒水，如果 TakeAction() 返回成功，说明倒水动作成立，可以通过本次倒水动作产生一个新状态（记录在 next 中）

然后对 next 进行检查，判断其是否是 states 队列中已经处理过的状态，如果 states 队列中已经存在这个状态，则不记录这个状态，继续对下一个动作进行尝试。

如果 next 是个新状态，则将其加入到 states 队列中，并通过递归调用 SearchState() 函数实现深度优先遍历。

```c++
void SearchState(std::deque<BucketsState>& states)
{
    BucketsState current = states.back(); // 每次都从当前状态开始
    if(IsFinalState(current))
    {
        PrineResult(states);
        return;
    }
    
    // 遍历倒水动作搜索新的状态
    for (const auto& act : action_table)
    {
        BucketsState next;
        /*从 from 到 to 倒水，如果成功，next 返回倒水后的状态*/
        if (current.TakeAction(act.first, act.second, next))
        {
            if (!IsProcessedState(states, next)) //新状态 next 不是重复状态
            {
                states.push_back(next); //新状态 next 加入队列
                SearchState(states); //从新的位置继续搜索
                states.pop_back(); //新状态 next 已经搜索完毕，回溯到上一级
            }
        }
    }
}
```



#### 倒水动作代码

倒水动作的具体代码实现在 BucketsState::TakeAction() 函数中，这也是一个很有意思的实现细节

能倒水的前提是 from 对应的桶中有水且 to 对应的桶中还有空间。

具体能倒多少水由 from 中的水和 to 中的空间共同决定，最后在返回新状态 next 之前，把产生的倒水动作记录到 next 中。

```c++
/*从 from 到 to 倒水，返回成功，得到新的状态 next*/
bool BucketsState::TakeAction(int from, int to, BucketsState& next)
{
    next = *this; //复制当前状态

    Bucket& bfrom = next.GetBucket(from);
    Bucket& bto = next.GetBucket(to);
    if ((bfrom.GetWater() > 0) && !bto.IsFull())
    {
        //能倒的水量由 from 剩的水量和 to 剩的空间决定
        int dump_water = (bfrom.GetWater() > bto.GetSpace()) ? bto.GetSpace() : bfrom.GetWater();
        bto.AddWater(dump_water);
        bfrom.DumpWater(dump_water);
        next.SetAction(dump_water, from, to); //记录当前倒水动作（输出结果需要）

        return true;
    }

    return false;
}
```

这一课我们介绍了一种树状空间的穷举搜索方法，这个问题和一般的遍历穷举不同之处在于问题的状态是静态的，需要一个“动作”才能完成状态的转换，产生新的状态。

因此遍历算法实际上不是直接对状态进行遍历，而是对“动作”进行遍历，然后将动作与状态叠加，从而产生新的状态。

这一课的算法实现有三个重点希望大家可以理解到，

第一个重点是通过循环处理 `action_table` 表实现对动作的遍历，这是个常用的技巧，希望大家掌握（可以对比书中的2重循环代码理解 action_table 表的好处）。

第二个重点是状态搜索的主体算法实现 SearchState() 函数，这里用了递归实现方式，利用 C++ 的 std::queue 队列提供的 push() 和 pop() 接口实现了状态的深度优先搜索和回溯（其他编程语言都提供了队列的实现，转换起来并不难理解）。

第三个重点是很有意思的倒水动作 TakeAction() 函数，它实现了对倒水过程中出现的两种情况的处理，即能不能倒水、能倒多少水，同时还记录了此次倒水产生的 ACTION。

好了，本课的问题也来了，就是电影中的题目，没有刻度的 3 加仑水桶和 5 加仑水桶各一个，水无限使用，可以随时倒掉，也可以随时装满，请你替约翰找找到底有几种倒腾出 4 升水的方法。